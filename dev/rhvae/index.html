<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>RHVAE · AutoEncode</title><meta name="title" content="RHVAE · AutoEncode"/><meta property="og:title" content="RHVAE · AutoEncode"/><meta property="twitter:title" content="RHVAE · AutoEncode"/><meta name="description" content="Documentation for AutoEncode."/><meta property="og:description" content="Documentation for AutoEncode."/><meta property="twitter:description" content="Documentation for AutoEncode."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img class="docs-light-only" src="../assets/logo.svg" alt="AutoEncode logo"/><img class="docs-dark-only" src="../assets/logo-dark.svg" alt="AutoEncode logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">AutoEncode</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../encoders/">Encoders &amp; Decoders</a></li><li><a class="tocitem" href="../ae/">Deterministic Autoencoders</a></li><li><a class="tocitem" href="../vae/">VAE / β-VAE</a></li><li><a class="tocitem" href="../mmdvae/">MMD-VAE (InfoVAE)</a></li><li><a class="tocitem" href="../infomaxvae/">InfoMax-VAE</a></li><li><a class="tocitem" href="../hvae/">HVAE</a></li><li class="is-active"><a class="tocitem" href>RHVAE</a><ul class="internal"><li><a class="tocitem" href="#Reference"><span>Reference</span></a></li><li><a class="tocitem" href="#MetricChain"><span><code>MetricChain</code> struct</span></a></li><li><a class="tocitem" href="#RHVAEstruct"><span><code>RHVAE</code> struct</span></a></li><li><a class="tocitem" href="#Forward-pass"><span>Forward pass</span></a></li><li><a class="tocitem" href="#Loss-function"><span>Loss function</span></a></li><li><a class="tocitem" href="#Training"><span>Training</span></a></li><li><a class="tocitem" href="#gradhamiltonian"><span>Computing the gradient of the potential energy</span></a></li><li><a class="tocitem" href="#Other-Functions"><span>Other Functions</span></a></li><li><a class="tocitem" href="#Default-initializations"><span>Default initializations</span></a></li></ul></li><li><a class="tocitem" href="../diffgeo/">Differential Geometry</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>RHVAE</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>RHVAE</a></li></ul></nav><div class="docs-right"><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="RHVAEsmodule"><a class="docs-heading-anchor" href="#RHVAEsmodule">Riemannian Hamiltonian Variational Autoencoder</a><a id="RHVAEsmodule-1"></a><a class="docs-heading-anchor-permalink" href="#RHVAEsmodule" title="Permalink"></a></h1><p>The Riemannian Hamiltonian Variational Autoencoder (RHVAE) is a variant of the Hamiltonian Variational Autoencoder (HVAE) that uses concepts from Riemannian geometry to improve the sampling of the latent space representation. As the HVAE, the RHVAE uses Hamiltonian dynamics to improve the sampling of the latent. However, the RHVAE accounts for the geometry of the latent space by learning a Riemannian metric tensor that is used to compute the kinetic energy of the dynamical system. This allows the RHVAE to sample the latent space more evenly while learning the curvature of the latent space.</p><p>For the implementation of the RHVAE in <code>AutoEncode.jl</code>, the <a href="#RHVAEstruct"><code>RHVAE</code></a> requires two arguments to construct: the original <a href="../vae/#VAEstruct"><code>VAE</code></a> as well as a separate neural network used to compute the metric tensor. To facilitate the dispatch of the necessary functions associated with this second network, we also provide a <a href="#MetricChain"><code>MetricChain</code></a> struct.</p><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>HVAEs require the computation of nested gradients. This means that the AutoDiff framework must differentiate a function of an already AutoDiff differentiated function. This is known to be problematic for <code>Julia</code>&#39;s AutoDiff backends. See <a href="#gradhamiltonian">details below</a> to understand how to we circumvent this problem.</p></div></div><h2 id="Reference"><a class="docs-heading-anchor" href="#Reference">Reference</a><a id="Reference-1"></a><a class="docs-heading-anchor-permalink" href="#Reference" title="Permalink"></a></h2><blockquote><p>Chadebec, C., Mantoux, C. &amp; Allassonnière, S. Geometry-Aware Hamiltonian Variational Auto-Encoder. Preprint at http://arxiv.org/abs/2010.11518 (2020).</p></blockquote><h2 id="MetricChain"><a class="docs-heading-anchor" href="#MetricChain"><code>MetricChain</code> struct</a><a id="MetricChain-1"></a><a class="docs-heading-anchor-permalink" href="#MetricChain" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AutoEncode.RHVAEs.MetricChain" href="#AutoEncode.RHVAEs.MetricChain"><code>AutoEncode.RHVAEs.MetricChain</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">MetricChain &lt;: AbstractMetricChain</code></pre><p>A <code>MetricChain</code> is used to compute the Riemannian metric tensor in the latent space of a Riemannian Hamiltonian Variational AutoEncoder (RHVAE).</p><p><strong>Fields</strong></p><ul><li><code>mlp::Flux.Chain</code>: A multi-layer perceptron (MLP) consisting of the hidden layers. The inputs are first run through this MLP.</li><li><code>diag::Flux.Dense</code>: A dense layer that computes the diagonal elements of a lower-triangular matrix. The output of the <code>mlp</code> is fed into this layer.</li><li><code>lower::Flux.Dense</code>: A dense layer that computes the off-diagonal elements of the lower-triangular matrix. The output of the <code>mlp</code> is also fed into this layer.</li></ul><p>The outputs of <code>diag</code> and <code>lower</code> are used to construct a lower-triangular matrix used to compute the Riemannian metric tensor in latent space.</p><p><strong>Note</strong></p><p>If the dimension of the latent space is <code>n</code>, the number of neurons in the output layer of <code>diag</code> must be <code>n</code>, and the number of neurons in the output layer of <code>lower</code> must be <code>n * (n - 1) ÷ 2</code>.</p><p><strong>Example</strong></p><pre><code class="language-julia hljs">mlp = Flux.Chain(Dense(10, 10, relu), Dense(10, 10, relu))
diag = Flux.Dense(10, 5)
lower = Flux.Dense(10, 15)
metric_chain = MetricChain(mlp, diag, lower)</code></pre></div></section></article><h2 id="RHVAEstruct"><a class="docs-heading-anchor" href="#RHVAEstruct"><code>RHVAE</code> struct</a><a id="RHVAEstruct-1"></a><a class="docs-heading-anchor-permalink" href="#RHVAEstruct" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AutoEncode.RHVAEs.RHVAE" href="#AutoEncode.RHVAEs.RHVAE"><code>AutoEncode.RHVAEs.RHVAE</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">RHVAE{
    V&lt;:VAE{&lt;:AbstractVariationalEncoder,&lt;:AbstractVariationalDecoder}
} &lt;: AbstractVariationalAutoEncoder</code></pre><p>A Riemannian Hamiltonian Variational AutoEncoder (RHVAE) as described in Chadebec, C., Mantoux, C. &amp; Allassonnière, S. Geometry-Aware Hamiltonian Variational Auto-Encoder. Preprint at http://arxiv.org/abs/2010.11518 (2020).</p><p>The RHVAE is a type of Variational AutoEncoder (VAE) that incorporates a Riemannian metric in the latent space. This metric is computed by a <code>MetricChain</code>, which is a struct that contains a multi-layer perceptron (MLP) and two dense layers for computing the elements of a lower-triangular matrix.</p><p>The inverse metric is computed as follows:</p><p>G⁻¹(z) = ∑ᵢ₌₁ⁿ L<em>ψᵢ L</em>ψᵢᵀ exp(-‖z - cᵢ‖₂² / T²) + λIₗ</p><p>where L_ψᵢ is computed by the <code>MetricChain</code>, T is the temperature, λ is a regularization factor, and each column of <code>centroids</code> are the cᵢ.</p><p><strong>Fields</strong></p><ul><li><code>vae::V</code>: The underlying VAE, where <code>V</code> is a subtype of <code>VAE</code> with an <code>AbstractVariationalEncoder</code> and an <code>AbstractVariationalDecoder</code>.</li><li><code>metric_chain::MetricChain</code>: The <code>MetricChain</code> that computes the Riemannian metric in the latent space.</li><li><code>centroids_data::AbstractArray</code>: An array where the last dimension represents a data point xᵢ from which the centroids cᵢ are computed by passing them through the encoder.</li><li><code>centroids_latent::AbstractMatrix</code>: A matrix where each column represents a centroid cᵢ in the inverse metric computation.</li><li><code>L::AbstractArray{&lt;:Number, 3}</code>: A 3D array where each slice represents a L<em>ψᵢ matrix. L</em>ψᵢ can intuitively be seen as the triangular matrix in the Cholesky decomposition of G⁻¹(centroids_latentᵢ) up to a regularization factor.</li><li><code>M::AbstractArray{&lt;:Number, 3}</code>: A 3D array where each slice represents a L<em>ψᵢ L</em>ψᵢᵀ.</li><li><code>T::Number</code>: The temperature parameter in the inverse metric computation.  </li><li><code>λ::Number</code>: The regularization factor in the inverse metric computation.</li></ul></div></section></article><h2 id="Forward-pass"><a class="docs-heading-anchor" href="#Forward-pass">Forward pass</a><a id="Forward-pass-1"></a><a class="docs-heading-anchor-permalink" href="#Forward-pass" title="Permalink"></a></h2><h3 id="Metric-Network"><a class="docs-heading-anchor" href="#Metric-Network">Metric Network</a><a id="Metric-Network-1"></a><a class="docs-heading-anchor-permalink" href="#Metric-Network" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AutoEncode.RHVAEs.MetricChain-Tuple{AbstractArray}" href="#AutoEncode.RHVAEs.MetricChain-Tuple{AbstractArray}"><code>AutoEncode.RHVAEs.MetricChain</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">(m::MetricChain)(x::AbstractArray; matrix::Bool=false)</code></pre><p>Perform a forward pass through the MetricChain.</p><p><strong>Arguments</strong></p><ul><li><code>x::AbstractArray</code>: The input data to be processed. </li><li><code>matrix::Bool=false</code>: A boolean flag indicating whether to return the result as a lower triangular matrix (if <code>true</code>) or as a tuple of diagonal and lower off-diagonal elements (if <code>false</code>). Defaults to <code>false</code>.</li></ul><p><strong>Returns</strong></p><ul><li>If <code>matrix</code> is <code>true</code>, returns a lower triangular matrix constructed from the outputs of the <code>diag</code> and <code>lower</code> components of the MetricChain.</li><li>If <code>matrix</code> is <code>false</code>, returns a <code>NamedTuple</code> with two elements: <code>diag</code>, the output of the <code>diag</code> component of the MetricChain, and <code>lower</code>, the output of the <code>lower</code> component of the MetricChain.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">m = MetricChain(...)
x = rand(Float32, 100, 10)
m(x, matrix=true)  # Returns a lower triangular matrix</code></pre></div></section></article><h3 id="RHVAE"><a class="docs-heading-anchor" href="#RHVAE">RHVAE</a><a id="RHVAE-1"></a><a class="docs-heading-anchor-permalink" href="#RHVAE" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AutoEncode.RHVAEs.RHVAE-Tuple{AbstractArray}" href="#AutoEncode.RHVAEs.RHVAE-Tuple{AbstractArray}"><code>AutoEncode.RHVAEs.RHVAE</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">(rhvae::RHVAE{VAE{E,D}})(
    x::AbstractArray;
    ϵ::Union{&lt;:Number,&lt;:AbstractVector}=Float32(1E-4),
    K::Int=3,
    βₒ::Number=0.3f0,
    ∇H::Function=∇hamiltonian_TaylorDiff,
    ∇H_kwargs::Union{NamedTuple,Dict}=(
            reconstruction_loglikelihood=decoder_loglikelihood,
            position_logprior=spherical_logprior,
            momentum_logprior=riemannian_logprior,
            G_inv=G_inv,
    ),
    tempering_schedule::Function=quadratic_tempering,
    latent::Bool=false,
) where where {E&lt;:AbstractGaussianLogEncoder,D&lt;:AbstractVariationalDecoder}</code></pre><p>Run the Riemannian Hamiltonian Variational Autoencoder (RHVAE) on the given input.</p><p><strong>Arguments</strong></p><ul><li><code>x::AbstractArray</code>: The input to the RHVAE. If it is a vector, it represents a single data point. If <code>Array,</code> the last dimension must contain each of the data points.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>K::Int=3</code>: The number of leapfrog steps to perform in the Hamiltonian Monte Carlo (HMC) part of the RHVAE.</li><li><code>ϵ::Union{&lt;:Number,&lt;:AbstractVector}=0.01f0</code>: The step size for the leapfrog steps in the HMC part of the RHVAE. If it is a scalar, the same step size is used for all dimensions. If it is an array, each element corresponds to the step size for a specific dimension.</li><li><code>βₒ::Number=0.3f0</code>: The initial inverse temperature for the tempering schedule.</li><li><code>steps::Int</code>: The number of fixed-point iterations to perform. Default is 3.</li><li><code>∇H::Function=∇hamiltonian_finite</code>: The function to compute the gradient of the Hamiltonian in the HMC part of the RHVAE.</li><li><code>∇H_kwargs::Union{NamedTuple,Dict}</code>: Additional keyword arguments to be passed to the <code>∇hamiltonian</code> function. Default is a NamedTuple with <code>reconstruction_loglikelihood</code>, <code>position_logprior</code>, and <code>momentum_logprior</code>.  </li><li><code>G_inv::Function=G_inv</code>: The function to compute the inverse of the Riemannian metric tensor.</li><li><code>tempering_schedule::Function=quadratic_tempering</code>: The function to compute the tempering schedule in the RHVAE.</li><li><code>latent::Bool=false</code>: If <code>true</code>, the function returns a NamedTuple containing the outputs of the encoder and decoder, and the final state of the phase space after the leapfrog and tempering steps. If <code>false</code>, the function only returns the output of the decoder.</li></ul><p><strong>Returns</strong></p><p>If <code>latent=true</code>, the function returns a NamedTuple with the following fields:</p><ul><li><code>encoder</code>: The outputs of the encoder.</li><li><code>decoder</code>: The output of the decoder.</li><li><code>phase_space</code>: The final state of the phase space after the leapfrog and   tempering steps.</li></ul><p>If <code>latent=false</code>, the function only returns the output of the decoder.</p><p><strong>Description</strong></p><p>This function runs the RHVAE on the given input. It first passes the input through the encoder to obtain the mean and log standard deviation of the latent space. It then uses the reparameterization trick to sample from the latent space. After that, it performs the leapfrog and tempering steps to refine the sample from the latent space. Finally, it passes the refined sample through the decoder to obtain the output.</p><p><strong>Notes</strong></p><p>Ensure that the dimensions of <code>x</code> match the input dimensions of the RHVAE, and that the dimensions of <code>ϵ</code> match the dimensions of the latent space.</p></div></section></article><h2 id="Loss-function"><a class="docs-heading-anchor" href="#Loss-function">Loss function</a><a id="Loss-function-1"></a><a class="docs-heading-anchor-permalink" href="#Loss-function" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AutoEncode.RHVAEs.loss" href="#AutoEncode.RHVAEs.loss"><code>AutoEncode.RHVAEs.loss</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">loss(
    rhvae::RHVAE,
    x::AbstractArray;
    K::Int=3,
    ϵ::Union{&lt;:Number,&lt;:AbstractVector}=Float32(1E-4),
    βₒ::Number=0.3f0,
    steps::Int=3,
    ∇H_kwargs::Union{NamedTuple,Dict}=(
        reconstruction_loglikelihood=decoder_loglikelihood,
        position_logprior=spherical_logprior,
        momentum_logprior=riemannian_logprior,
    ),
    G_inv::Function=G_inv,
    tempering_schedule::Function=quadratic_tempering,
    reg_function::Union{Function,Nothing}=nothing,
    reg_kwargs::Union{NamedTuple,Dict}=Dict(),
    reg_strength::Number=1.0f0,
    logp_prefactor::AbstractArray=ones(Float32, 3),
    logq_prefactor::AbstractArray=ones(Float32, 3),
)</code></pre><p>Compute the loss for a Riemannian Hamiltonian Variational Autoencoder (RHVAE).</p><p><strong>Arguments</strong></p><ul><li><code>rhvae::RHVAE</code>: The RHVAE used to encode the input data and decode the latent space.</li><li><code>x::AbstractArray</code>: Input data to the RHVAE encoder. The last dimension is taken as having each of the samples in a batch.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>K::Int</code>: The number of HMC steps (default is 3).</li><li><code>ϵ::Union{&lt;:Number,&lt;:AbstractVector}</code>: The step size for the leapfrog integrator (default is 0.001).</li><li><code>βₒ::Number</code>: The initial inverse temperature (default is 0.3).</li><li><code>steps::Int</code>: The number of steps in the leapfrog integrator (default is 3).</li><li><code>∇H_kwargs::Union{NamedTuple,Dict}</code>: Additional keyword arguments to be passed to the <code>∇hamiltonian</code> function.</li><li><code>G_inv::Function</code>: The function to compute the inverse of the Riemannian metric tensor (default is <code>G_inv</code>).</li><li><code>tempering_schedule::Function</code>: The tempering schedule function used in the HMC (default is <code>quadratic_tempering</code>).</li><li><code>reg_function::Union{Function, Nothing}=nothing</code>: A function that computes the regularization term based on the VAE outputs. This function must take as input the VAE outputs and the keyword arguments provided in <code>reg_kwargs</code>.</li><li><code>reg_kwargs::Union{NamedTuple,Dict}=Dict()</code>: Keyword arguments to pass to the regularization function.</li><li><code>reg_strength::Number=1.0f0</code>: The strength of the regularization term.</li><li><code>logp_prefactor::AbstractArray</code>: A 3-element array to scale the log likelihood, log prior of the latent variables, and log prior of the momentum variables. Default is an array of ones.</li><li><code>logq_prefactor::AbstractArray</code>: A 3-element array to scale the log posterior of the initial latent variables, log prior of the initial momentum variables, and the tempering Jacobian term. Default is an array of ones.</li></ul><p><strong>Returns</strong></p><ul><li>The computed loss.</li></ul></div></section><section><div><pre><code class="language-julia hljs">loss(
    rhvae::RHVAE,
    x_in::AbstractArray,
    x_out::AbstractArray;
    K::Int=3,
    ϵ::Union{&lt;:Number,&lt;:AbstractVector}=Float32(1E-4),
    βₒ::Number=0.3f0,
    steps::Int=3,
    ∇H_kwargs::Union{NamedTuple,Dict}=(
        reconstruction_loglikelihood=decoder_loglikelihood,
        position_logprior=spherical_logprior,
        momentum_logprior=riemannian_logprior,
    ),
    G_inv::Function=G_inv,
    tempering_schedule::Function=quadratic_tempering,
    reg_function::Union{Function,Nothing}=nothing,
    reg_kwargs::Union{NamedTuple,Dict}=Dict(),
    reg_strength::Number=1.0f0,
    logp_prefactor::AbstractArray=ones(Float32, 3),
    logq_prefactor::AbstractArray=ones(Float32, 3),
)</code></pre><p>Compute the loss for a Riemannian Hamiltonian Variational Autoencoder (RHVAE).</p><p><strong>Arguments</strong></p><ul><li><code>rhvae::RHVAE</code>: The RHVAE used to encode the input data and decode the latent space.</li><li><code>x_in::AbstractArray</code>: Input data to the RHVAE encoder. The last dimension is taken as having each of the samples in a batch.</li><li><code>x_out::AbstractArray</code>: Target data to compute the reconstruction error. The last dimension is taken as having each of the samples in a batch.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>K::Int</code>: The number of HMC steps (default is 3).</li><li><code>ϵ::Union{&lt;:Number,&lt;:AbstractVector}</code>: The step size for the leapfrog integrator (default is 0.001).</li><li><code>βₒ::Number</code>: The initial inverse temperature (default is 0.3).</li><li><code>steps::Int</code>: The number of steps in the leapfrog integrator (default is 3).</li><li><code>∇H_kwargs::Union{NamedTuple,Dict}</code>: Additional keyword arguments to be passed to the <code>∇hamiltonian</code> function.</li><li><code>G_inv::Function</code>: The function to compute the inverse of the Riemannian metric tensor (default is <code>G_inv</code>).</li><li><code>tempering_schedule::Function</code>: The tempering schedule function used in the HMC (default is <code>quadratic_tempering</code>).</li><li><code>reg_function::Union{Function, Nothing}=nothing</code>: A function that computes the regularization term based on the VAE outputs. This function must take as input the VAE outputs and the keyword arguments provided in <code>reg_kwargs</code>.</li><li><code>reg_kwargs::Union{NamedTuple,Dict}=Dict()</code>: Keyword arguments to pass to the regularization function.</li><li><code>reg_strength::Number=1.0f0</code>: The strength of the regularization term.</li><li><code>logp_prefactor::AbstractArray</code>: A 3-element array to scale the log likelihood, log prior of the latent variables, and log prior of the momentum variables. Default is an array of ones.</li><li><code>logq_prefactor::AbstractArray</code>: A 3-element array to scale the log posterior of the initial latent variables, log prior of the initial momentum variables, and the tempering Jacobian term. Default is an array of ones.</li></ul><p><strong>Returns</strong></p><ul><li>The computed loss.</li></ul></div></section></article><h2 id="Training"><a class="docs-heading-anchor" href="#Training">Training</a><a id="Training-1"></a><a class="docs-heading-anchor-permalink" href="#Training" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AutoEncode.RHVAEs.train!" href="#AutoEncode.RHVAEs.train!"><code>AutoEncode.RHVAEs.train!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">train!(
    rhvae::RHVAE, 
    x::AbstractArray, 
    opt::NamedTuple; 
    loss_function::Function=loss, 
    loss_kwargs::Union{NamedTuple,Dict}=Dict(),
    verbose::Bool=false,
    loss_return::Bool=false,
)</code></pre><p>Customized training function to update parameters of a Riemannian Hamiltonian Variational Autoencoder given a specified loss function.</p><p><strong>Arguments</strong></p><ul><li><code>rhvae::RHVAE</code>: A struct containing the elements of a Riemannian Hamiltonian Variational Autoencoder.</li><li><code>x::AbstractArray</code>: Input data to the RHVAE encoder. The last dimension is taken as having each of the samples in a batch.</li><li><code>opt::NamedTuple</code>: State of the optimizer for updating parameters. Typically initialized using <code>Flux.Optimisers.update!</code>.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>loss_function::Function=loss</code>: The loss function used for training. It should accept the RHVAE model, data <code>x</code>, and keyword arguments in that order.</li><li><code>loss_kwargs::Dict=Dict()</code>: Arguments for the loss function. These might include parameters like <code>K</code>, <code>ϵ</code>, <code>βₒ</code>, <code>steps</code>, <code>∇H</code>, <code>∇H_kwargs</code>, <code>tempering_schedule</code>, <code>reg_function</code>, <code>reg_kwargs</code>, <code>reg_strength</code>, depending on the specific loss function in use.</li><li><code>verbose::Bool=false</code>: Whether to print the loss at each iteration.</li><li><code>loss_return::Bool=false</code>: Whether to return the loss at each iteration.</li></ul><p><strong>Description</strong></p><p>Trains the RHVAE by:</p><ol><li>Computing the gradient of the loss w.r.t the RHVAE parameters.</li><li>Updating the RHVAE parameters using the optimizer.</li><li>Updating the metric parameters.</li></ol></div></section><section><div><pre><code class="language-julia hljs">train!(
    rhvae::RHVAE, 
    x_in::AbstractArray,
    x_out::AbstractArray,
    opt::NamedTuple; 
    loss_function::Function=loss, 
    loss_kwargs::Union{NamedTuple,Dict}=Dict(),
    verbose::Bool=false,
    loss_return::Bool=false,
)</code></pre><p>Customized training function to update parameters of a Riemannian Hamiltonian Variational Autoencoder given a specified loss function.</p><p><strong>Arguments</strong></p><ul><li><code>rhvae::RHVAE</code>: A struct containing the elements of a Riemannian Hamiltonian Variational Autoencoder.</li><li><code>x_in::AbstractArray</code>: Input data to the RHVAE encoder. The last dimension is taken as having each of the samples in a batch.</li><li><code>x_out::AbstractArray</code>: Target data to compute the reconstruction error. The last dimension is taken as having each of the samples in a batch.</li><li><code>opt::NamedTuple</code>: State of the optimizer for updating parameters. Typically initialized using <code>Flux.Optimisers.update!</code>.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>loss_function::Function=loss</code>: The loss function used for training. It should accept the RHVAE model, data <code>x</code>, and keyword arguments in that order.</li><li><code>loss_kwargs::Dict=Dict()</code>: Arguments for the loss function. These might include parameters like <code>K</code>, <code>ϵ</code>, <code>βₒ</code>, <code>steps</code>, <code>∇H</code>, <code>∇H_kwargs</code>, <code>tempering_schedule</code>, <code>reg_function</code>, <code>reg_kwargs</code>, <code>reg_strength</code>, depending on the specific loss function in use.</li><li><code>verbose::Bool=false</code>: Whether to print the loss at each iteration.</li><li><code>loss_return::Bool=false</code>: Whether to return the loss at each iteration.</li></ul><p><strong>Description</strong></p><p>Trains the RHVAE by:</p><ol><li>Computing the gradient of the loss w.r.t the RHVAE parameters.</li><li>Updating the RHVAE parameters using the optimizer.</li><li>Updating the metric parameters.</li></ol></div></section></article><h2 id="gradhamiltonian"><a class="docs-heading-anchor" href="#gradhamiltonian">Computing the gradient of the potential energy</a><a id="gradhamiltonian-1"></a><a class="docs-heading-anchor-permalink" href="#gradhamiltonian" title="Permalink"></a></h2><p>One of the crucial components in the training of the RHVAE is the computation of the gradient of the Hamiltonian <span>$\nabla H$</span> with respect to the latent space representation. This gradient is used in the leapfrog steps of the generalized Hamiltonian dynamics. When training the RHVAE, we need to backpropagate through the leapfrog steps to update the parameters of the neural network. This requires computing a gradient of a function of the gradient of the Hamiltonian, i.e., nested gradients. <code>Zygote.jl</code> the main AutoDiff backend in <code>Flux.jl</code> <a href="https://discourse.julialang.org/t/is-it-possible-to-do-nested-ad-elegantly-in-julia-pinns/98888">famously struggle</a> with these types of computations. Specifically, <code>Zygote.jl</code> does not support <code>Zygote</code> over <code>Zygote</code> differentiation (meaning differentiating a function of something previously differentiated with <code>Zygote</code> using <code>Zygote</code>), or <code>Zygote</code> over <code>ForwardDiff</code> (meaning differentiating a function of something differentiated with <code>ForwardDiff</code> using <code>Zygote</code>).</p><p>With this, we are left with a couple of options to compute the gradient of the potential energy:</p><ul><li>Use finite differences to approximate the gradient of the potential energy.</li><li>Use the relatively new <a href="https://github.com/JuliaDiff/TaylorDiff.jl/tree/main"><code>TaylorDiff.jl</code></a> AutoDiff backend to compute the gradient of the potential energy. This backend is composable with <code>Zygote.jl</code>, so we can, in principle, do <code>Zygote</code> over <code>TaylorDiff</code> differentiation.</li></ul><p>The second option would be preferred, as the gradients computed with <code>TaylorDiff</code> are much more accurate than the ones computed with finite differences. However, there are two problems with this approach:</p><ol><li>The <code>TaylorDiff</code> nested gradient capability stopped working with <code>Julia ≥  1.10</code>, as discussed in  <a href="https://github.com/JuliaDiff/TaylorDiff.jl/issues/70">#70</a>.</li><li>Even for <code>Julia &lt; 1.10</code>, we could not get <code>TaylorDiff</code> to work on <code>CUDA</code>  devices. (PRs are welcome!)</li></ol><p>With these limitations in mind, we have implemented the gradient of the potential using both finite differences and <code>TaylorDiff</code>. The user can choose which method to use by setting the <code>adtype</code> keyword argument in the <code>∇H_kwargs</code> in the <code>loss</code> function to either <code>:finite</code> or <code>:TaylorDiff</code>. This means that for the <code>train!</code> function, the user can pass <code>loss_kwargs</code> that looks like this:</p><pre><code class="language-julia hljs"># Define the autodiff backend to use
loss_kwargs = Dict(
    :∇H_kwargs =&gt; Dict(
        :adtype =&gt; :finite
    )
)</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Although verbose, the nested dictionaries help to keep everything organized. (PRs with better design ideas are welcome!)</p></div></div><p>The default both for <code>cpu</code> and <code>gpu</code> devices is <code>:finite</code>.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AutoEncode.RHVAEs.∇hamiltonian_finite" href="#AutoEncode.RHVAEs.∇hamiltonian_finite"><code>AutoEncode.RHVAEs.∇hamiltonian_finite</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">∇hamiltonian_finite(
    x::AbstractArray,
    z::AbstractVecOrMat,
    ρ::AbstractVecOrMat,
    G⁻¹::AbstractArray,
    logdetG::Union{&lt;:Number,AbstractVector},
    decoder::AbstractVariationalDecoder,
    decoder_output::NamedTuple,
    var::Symbol;
    reconstruction_loglikelihood::Function=decoder_loglikelihood,
    position_logprior::Function=spherical_logprior,
    momentum_logprior::Function=riemannian_logprior,
    fdtype::Symbol=:central,
)</code></pre><p>Compute the gradient of the Hamiltonian with respect to a given variable using a naive finite difference method.</p><p>This function takes a point <code>x</code> in the data space, a point <code>z</code> in the latent space, a momentum <code>ρ</code>, the inverse of the Riemannian metric tensor <code>G⁻¹</code>, a <code>decoder</code> of type <code>AbstractVariationalDecoder</code>, a <code>decoder_output</code> NamedTuple, and a variable <code>var</code> (:z or :ρ), and computes the gradient of the Hamiltonian with respect to <code>var</code> using a simple finite differences method. The computation is based on the log-likelihood of the decoder, the log-prior of the latent space, and <code>G⁻¹</code>.</p><p>The Hamiltonian is computed as follows:</p><p>Hₓ(z, ρ) = Uₓ(z) + κ(ρ),</p><p>where Uₓ(z) is the potential energy, and κ(ρ) is the kinetic energy. The potential energy is defined as follows:</p><p>Uₓ(z) = -log p(x|z) - log p(z),</p><p>where p(x|z) is the log-likelihood of the decoder and p(z) is the log-prior in latent space. The kinetic energy is defined as follows:</p><p>κ(ρ) = 0.5 * log((2π)ᴰ det G(z)) + 0.5 * ρᵀ G⁻¹ ρ</p><p>where D is the dimension of the latent space, and G(z) is the metric tensor at the point <code>z</code>.</p><p><strong>Arguments</strong></p><ul><li><code>x::AbstractArray</code>: The point in the data space. This does not necessarily need to be a vector. Array inputs are supported. The last dimension is assumed to have each of the data points.</li><li><code>z::AbstractVecOrMat</code>: The point in the latent space. If matrix, each column represents a point in the latent space.</li><li><code>ρ::AbstractVecOrMat</code>: The momentum. If matrux, each column represents a momentum vector.</li><li><code>G⁻¹::AbstractArray</code>: The inverse of the Riemannian metric tensor. If 3D array, each slice along the third dimension represents the inverse of the metric tensor at the corresponding column of <code>z</code>.</li><li><code>logdetG::Union{&lt;:Number,AbstractVector}</code>: The log determinant of the Riemannian metric tensor. If vector, each element represents the log determinant of the metric tensor at the corresponding column of <code>z</code>.</li><li><code>decoder::AbstractVariationalDecoder</code>: The decoder instance.</li><li><code>decoder_output::NamedTuple</code>: The output of the decoder.</li><li><code>var::Symbol</code>: The variable with respect to which the gradient is computed. Must be :z or :ρ.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>reconstruction_loglikelihood::Function</code>: The function to compute the log-likelihood of the decoder reconstruction. Default is <code>decoder_loglikelihood</code>. This function must take as input the decoder, the point <code>x</code> in the data space, and the <code>decoder_output</code>.</li><li><code>position_logprior::Function</code>: The function to compute the log-prior of the latent space position. Default is <code>spherical_logprior</code>. This function must take as input the point <code>z</code> in the latent space.</li><li><code>momentum_logprior::Function</code>: The function to compute the log-prior of the momentum. Default is <code>riemannian_logprior</code>. This function must take as input the momentum <code>ρ</code> and <code>G⁻¹</code>.</li><li><code>fdtype::Symbol=:central</code>: The type of finite difference method to use. Must be :central or :forward. Default is :central.</li></ul><p><strong>Returns</strong></p><p>A vector representing the gradient of the Hamiltonian at the point <code>(z, ρ)</code> with respect to variable <code>var</code>.</p></div></section><section><div><pre><code class="language-julia hljs">∇hamiltonian_finite(
    x::AbstractArray,
    z::AbstractVecOrMat,
    ρ::AbstractVecOrMat,
    rhvae::RHVAE,
    var::Symbol;
    reconstruction_loglikelihood::Function=decoder_loglikelihood,
    position_logprior::Function=spherical_logprior,
    momentum_logprior::Function=riemannian_logprior,
    G_inv::Function=G_inv,
    fdtype::Symbol=:central,
)</code></pre><p>Compute the gradient of the Hamiltonian with respect to a given variable using a naive finite difference method.</p><p>This function takes a point <code>x</code> in the data space, a point <code>z</code> in the latent space, a momentum <code>ρ</code>, an instance of <code>RHVAE</code>, and a variable <code>var</code> (:z or :ρ), and computes the gradient of the Hamiltonian with respect to <code>var</code> using a simple finite differences method. The computation is based on the log-likelihood of the decoder, the log-prior of the latent space, and the inverse of the metric tensor G at the point <code>z</code>.</p><p>The Hamiltonian is computed as follows:</p><p>Hₓ(z, ρ) = Uₓ(z) + κ(ρ),</p><p>where Uₓ(z) is the potential energy, and κ(ρ) is the kinetic energy. The potential energy is defined as follows:</p><p>Uₓ(z) = -log p(x|z) - log p(z),</p><p>where p(x|z) is the log-likelihood of the decoder and p(z) is the log-prior in latent space. The kinetic energy is defined as follows:</p><p>κ(ρ) = 0.5 * log((2π)ᴰ det G(z)) + 0.5 * ρᵀ G⁻¹ ρ</p><p>where D is the dimension of the latent space, and G(z) is the metric tensor at the point <code>z</code>.</p><p><strong>Arguments</strong></p><ul><li><code>x::AbstractArray</code>: The point in the data space. This does not necessarily need to be a vector. Array inputs are supported. The last dimension is assumed to have each of the data points.</li><li><code>z::AbstractVecOrMat</code>: The point in the latent space. If matrix, each column represents a point in the latent space.</li><li><code>ρ::AbstractVecOrMat</code>: The momentum. If matrux, each column represents a momentum vector.</li><li><code>rhvae::RHVAE</code>: An instance of the RHVAE model.</li><li><code>var::Symbol</code>: The variable with respect to which the gradient is computed. Must be :z or :ρ.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>reconstruction_loglikelihood::Function</code>: The function to compute the log-likelihood of the decoder reconstruction. Default is <code>decoder_loglikelihood</code>. This function must take as input the decoder, the point <code>x</code> in the data space, and the <code>decoder_output</code>.</li><li><code>position_logprior::Function</code>: The function to compute the log-prior of the latent space position. Default is <code>spherical_logprior</code>. This function must take as input the point <code>z</code> in the latent space.</li><li><code>momentum_logprior::Function</code>: The function to compute the log-prior of the momentum. Default is <code>riemannian_logprior</code>. This function must take as input the momentum <code>ρ</code> and the inverse of the Riemannian metric tensor <code>G⁻¹</code>.</li><li><code>G_inv::Function</code>: The function to compute the inverse of the Riemannian metric tensor. Default is <code>G_inv</code>. This function must take as input the point <code>z</code> in the latent space and the <code>rhvae</code> instance.</li><li><code>fdtype::Symbol=:central</code>: The type of finite difference method to use. Must be :central or :forward. Default is :central.</li></ul><p><strong>Returns</strong></p><p>A vector representing the gradient of the Hamiltonian at the point <code>(z, ρ)</code> with respect to variable <code>var</code>.</p><p><strong>Note</strong></p><p>The inverse of the Riemannian metric tensor <code>G⁻¹</code>, the log determinant of the metric tensor, and the output of the decoder are computed internally in this function. The user does not need to provide these as inputs.</p></div></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AutoEncode.RHVAEs.∇hamiltonian_TaylorDiff" href="#AutoEncode.RHVAEs.∇hamiltonian_TaylorDiff"><code>AutoEncode.RHVAEs.∇hamiltonian_TaylorDiff</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">∇hamiltonian_TaylorDiff(
    x::AbstractArray,
    z::AbstractVector,
    ρ::AbstractVector,
    G⁻¹::AbstractMatrix,
    logdetG::Union{&lt;:Number,AbstractVector},
    decoder::AbstractVariationalDecoder,
    decoder_output::NamedTuple,
    var::Symbol;
    reconstruction_loglikelihood::Function=decoder_loglikelihood,
    position_logprior::Function=spherical_logprior,
    momentum_logprior::Function=riemannian_logprior,
)</code></pre><p>Compute the gradient of the Hamiltonian with respect to a given variable using the TaylorDiff.jl automatic differentiation library.</p><p>This function takes a point <code>x</code> in the data space, a point <code>z</code> in the latent space, a momentum <code>ρ</code>, an instance of <code>AbstractVariationalDecoder</code>, and a variable <code>var</code> (:z or :ρ), and computes the gradient of the Hamiltonian with respect to <code>var</code> using TaylorDiff.jl.</p><p>The Hamiltonian is computed as follows:</p><p>Hₓ(z, ρ) = Uₓ(z) + κ(ρ),</p><p>where Uₓ(z) is the potential energy, and κ(ρ) is the kinetic energy. The potential energy is defined as follows:</p><p>Uₓ(z) = -log p(x|z) - log p(z),</p><p>where p(x|z) is the log-likelihood of the decoder and p(z) is the log-prior in latent space. The kinetic energy is defined as follows:</p><p>κ(ρ) = 0.5 * log((2π)ᴰ det G(z)) + 0.5 * ρᵀ G⁻¹ ρ</p><p>where D is the dimension of the latent space, and G(z) is the metric tensor at the point <code>z</code>.</p><p><strong>Arguments</strong></p><ul><li><code>x::AbstractArray</code>: The point in the data space. This does not necessarily need to be a vector. Array inputs are supported. The last dimension is assumed to have each of the data points.</li><li><code>z::AbstractVector</code>: The point in the latent space.</li><li><code>ρ::AbstractVector</code>: The momentum.</li><li><code>G⁻¹::AbstractMatrix</code>: The inverse of the Riemannian metric tensor.</li><li><code>logdetG::Number</code>: The logarithm of the determinant of the Riemannian metric tensor.</li><li><code>decoder::AbstractVariationalDecoder</code>: An instance of the decoder model.</li><li><code>decoder_output::NamedTuple</code>: The output of the decoder model.</li><li><code>var::Symbol</code>: The variable with respect to which the gradient is computed. Must be :z or :ρ.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>reconstruction_loglikelihood::Function</code>: The function to compute the log-likelihood of the decoder reconstruction. Default is <code>decoder_loglikelihood</code>. This function must take as input the decoder, the point <code>x</code> in the data space, and the <code>decoder_output</code>.</li><li><code>position_logprior::Function</code>: The function to compute the log-prior of the latent space position. Default is <code>spherical_logprior</code>. This function must take as input the point <code>z</code> in the latent space.</li><li><code>momentum_logprior::Function</code>: The function to compute the log-prior of the momentum. Default is <code>riemannian_logprior</code>. This function must take as input the momentum <code>ρ</code> and the inverse of the Riemannian metric tensor <code>G⁻¹</code>.</li></ul><p><strong>Returns</strong></p><p>A vector representing the gradient of the Hamiltonian at the point <code>(z, ρ)</code> with respect to variable <code>var</code>.</p><p><strong>Note</strong></p><p><code>TaylorDiff.jl</code> is composable with <code>Zygote.jl.</code> Thus, for backpropagation using this function one should use <code>Zygote.jl.</code></p></div></section><section><div><pre><code class="language-julia hljs">∇hamiltonian_TaylorDiff(
    x::AbstractArray,
    z::AbstractVecOrMat,
    ρ::AbstractVecOrMat,
    rhvae::RHVAE,
    var::Symbol;
    reconstruction_loglikelihood::Function=decoder_loglikelihood,
    position_logprior::Function=spherical_logprior,
    momentum_logprior::Function=riemannian_logprior,
    G_inv::Function=G_inv,
)</code></pre><p>Compute the gradient of the Hamiltonian with respect to a given variable using the TaylorDiff.jl automatic differentiation library.</p><p>This function takes a point <code>x</code> in the data space, a point <code>z</code> in the latent space, a momentum <code>ρ</code>, an instance of <code>RHVAE</code>, and a variable <code>var</code> (:z or :ρ), and computes the gradient of the Hamiltonian with respect to <code>var</code> using TaylorDiff.jl.</p><p>The Hamiltonian is computed as follows:</p><p>Hₓ(z, ρ) = Uₓ(z) + κ(ρ),</p><p>where Uₓ(z) is the potential energy, and κ(ρ) is the kinetic energy. The potential energy is defined as follows:</p><p>Uₓ(z) = -log p(x|z) - log p(z),</p><p>where p(x|z) is the log-likelihood of the decoder and p(z) is the log-prior in latent space. The kinetic energy is defined as follows:</p><p>κ(ρ) = 0.5 * log((2π)ᴰ det G(z)) + 0.5 * ρᵀ G⁻¹ ρ</p><p>where D is the dimension of the latent space, and G(z) is the metric tensor at the point <code>z</code>.</p><p><strong>Arguments</strong></p><ul><li><code>x::AbstractArray</code>: The point in the data space. This does not necessarily need to be a vector. Array inputs are supported. The last dimension is assumed to have each of the data points.</li><li><code>z::AbstractVecOrMat</code>: The point in the latent space. If matrix, each column represents a point in the latent space.</li><li><code>ρ::AbstractVecOrMat</code>: The momentum. If matrix, each column represents a momentum vector.</li><li><code>rhvae::RHVAE</code>: An instance of the RHVAE model.</li><li><code>var::Symbol</code>: The variable with respect to which the gradient is computed. Must be :z or :ρ.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>reconstruction_loglikelihood::Function</code>: The function to compute the log-likelihood of the decoder reconstruction. Default is <code>decoder_loglikelihood</code>. This function must take as input the decoder, the point <code>x</code> in the data space, and the <code>decoder_output</code>.</li><li><code>position_logprior::Function</code>: The function to compute the log-prior of the latent space position. Default is <code>spherical_logprior</code>. This function must take as input the point <code>z</code> in the latent space.</li><li><code>momentum_logprior::Function</code>: The function to compute the log-prior of the momentum. Default is <code>riemannian_logprior</code>. This function must take as input the momentum <code>ρ</code> and the inverse of the Riemannian metric tensor <code>G⁻¹</code>.</li><li><code>G_inv::Function</code>: The function to compute the inverse of the Riemannian metric tensor. Default is <code>G_inv</code>. This function must take as input the point <code>z</code> in the latent space and the <code>rhvae</code> instance.</li></ul><p><strong>Returns</strong></p><p>A matrix representing the gradient of the Hamiltonian at the point <code>(z, ρ)</code> with respect to variable <code>var</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AutoEncode.RHVAEs.∇hamiltonian_ForwardDiff" href="#AutoEncode.RHVAEs.∇hamiltonian_ForwardDiff"><code>AutoEncode.RHVAEs.∇hamiltonian_ForwardDiff</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">∇hamiltonian_ForwardDiff(
    x::AbstractArray,
    z::AbstractVector,
    ρ::AbstractVector,
    G⁻¹::AbstractMatrix,
    logdetG::Union{&lt;:Number,AbstractVector},
    decoder::AbstractVariationalDecoder,
    decoder_output::NamedTuple,
    var::Symbol;
    reconstruction_loglikelihood::Function=decoder_loglikelihood,
    position_logprior::Function=spherical_logprior,
    momentum_logprior::Function=riemannian_logprior,
)</code></pre><p>Compute the gradient of the Hamiltonian with respect to a given variable using the ForwardDiff.jl automatic differentiation library.</p><p>This function takes a point <code>x</code> in the data space, a point <code>z</code> in the latent space, a momentum <code>ρ</code>, the inverse of the Riemannian metric tensor <code>G⁻¹</code>, a <code>decoder</code> of type <code>AbstractVariationalDecoder</code>, a <code>decoder_output</code> NamedTuple, and a variable <code>var</code> (:z or :ρ), and computes the gradient of the Hamiltonian with respect to <code>var</code> using ForwardDiff.jl.</p><p>The Hamiltonian is computed as follows:</p><p>Hₓ(z, ρ) = Uₓ(z) + κ(ρ),</p><p>where Uₓ(z) is the potential energy, and κ(ρ) is the kinetic energy. The potential energy is defined as follows:</p><p>Uₓ(z) = -log p(x|z) - log p(z),</p><p>where p(x|z) is the log-likelihood of the decoder and p(z) is the log-prior in latent space. The kinetic energy is defined as follows:</p><p>κ(ρ) = 0.5 * log((2π)ᴰ det G(z)) + 0.5 * ρᵀ G⁻¹ ρ</p><p>where D is the dimension of the latent space, and G(z) is the metric tensor at the point <code>z</code>.</p><p><strong>Arguments</strong></p><ul><li><code>x::AbstractArray</code>: The point in the data space. This does not necessarily need to be a vector. Array inputs are supported. The last dimension is assumed to have each of the data points.</li><li><code>z::AbstractVector</code>: The point in the latent space.</li><li><code>ρ::AbstractVector</code>: The momentum.</li><li><code>G⁻¹::AbstractMatrix</code>: The inverse of the Riemannian metric tensor.</li><li><code>logdetG::Union{&lt;:Number,AbstractVector}</code>: The log determinant of the Riemannian metric tensor.</li><li><code>decoder::AbstractVariationalDecoder</code>: The decoder instance.</li><li><code>decoder_output::NamedTuple</code>: The output of the decoder.</li><li><code>var::Symbol</code>: The variable with respect to which the gradient is computed. Must be :z or :ρ.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>reconstruction_loglikelihood::Function</code>: The function to compute the log-likelihood of the decoder reconstruction. Default is <code>decoder_loglikelihood</code>. This function must take as input the decoder, the point <code>x</code> in the data space, and the <code>decoder_output</code>.</li><li><code>position_logprior::Function</code>: The function to compute the log-prior of the latent space position. Default is <code>spherical_logprior</code>. This function must take as input the point <code>z</code> in the latent space.</li><li><code>momentum_logprior::Function</code>: The function to compute the log-prior of the momentum. Default is <code>riemannian_logprior</code>. This function must take as input the momentum <code>ρ</code> and <code>G⁻¹</code>.</li></ul><p><strong>Returns</strong></p><p>A vector representing the gradient of the Hamiltonian at the point <code>(z, ρ)</code> with respect to variable <code>var</code>.</p><p><strong>Note</strong></p><p><code>ForwardDiff.jl</code> is not composable with <code>Zygote.jl.</code> Thus, for backpropagation using this function one should use <code>ReverseDiff.jl.</code></p></div></section><section><div><pre><code class="language-julia hljs">∇hamiltonian_ForwardDiff(
    x::AbstractArray,
    z::AbstractMatrix,
    ρ::AbstractMatrix,
    G⁻¹::AbstractArray,
    logdetG::Union{&lt;:Number,AbstractVector},
    decoder::AbstractVariationalDecoder,
    decoder_output::NamedTuple,
    var::Symbol;
    reconstruction_loglikelihood::Function=decoder_loglikelihood,
    position_logprior::Function=spherical_logprior,
    momentum_logprior::Function=riemannian_logprior,
)</code></pre><p>Compute the gradient of the Hamiltonian with respect to a given variable using the ForwardDiff.jl automatic differentiation library.</p><p>This function takes a point <code>x</code> in the data space, a point <code>z</code> in the latent space, a momentum <code>ρ</code>, the inverse of the Riemannian metric tensor <code>G⁻¹</code>, a <code>decoder</code> of type <code>AbstractVariationalDecoder</code>, a <code>decoder_output</code> NamedTuple, and a variable <code>var</code> (:z or :ρ), and computes the gradient of the Hamiltonian with respect to <code>var</code> using ForwardDiff.jl.</p><p>The Hamiltonian is computed as follows:</p><p>Hₓ(z, ρ) = Uₓ(z) + κ(ρ),</p><p>where Uₓ(z) is the potential energy, and κ(ρ) is the kinetic energy. The potential energy is defined as follows:</p><p>Uₓ(z) = -log p(x|z) - log p(z),</p><p>where p(x|z) is the log-likelihood of the decoder and p(z) is the log-prior in latent space. The kinetic energy is defined as follows:</p><p>κ(ρ) = 0.5 * log((2π)ᴰ det G(z)) + 0.5 * ρᵀ G⁻¹ ρ</p><p>where D is the dimension of the latent space, and G(z) is the metric tensor at the point <code>z</code>.</p><p>The Jacobian is computed with respect to <code>var</code> to compute derivatives for all columns at once. The relevant terms for each column&#39;s gradient are then extracted from the Jacobian.</p><p><strong>Arguments</strong></p><ul><li><code>x::AbstractArray</code>: The point in the data space. This does not necessarily need to be a vector. Array inputs are supported. The last dimension is assumed to have each of the data points.</li><li><code>z::AbstractMatrix</code>: The point in the latent space.</li><li><code>ρ::AbstractMatrix</code>: The momentum.</li><li><code>G⁻¹::AbstractArray</code>: The inverse of the Riemannian metric tensor.</li><li><code>logdetG::Union{&lt;:Number,AbstractVector}</code>: The log determinant of the Riemannian metric tensor.</li><li><code>decoder::AbstractVariationalDecoder</code>: The decoder instance.</li><li><code>decoder_output::NamedTuple</code>: The output of the decoder.</li><li><code>var::Symbol</code>: The variable with respect to which the gradient is computed. Must be :z or :ρ.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>reconstruction_loglikelihood::Function</code>: The function to compute the log-likelihood of the decoder reconstruction. Default is <code>decoder_loglikelihood</code>. This function must take as input the decoder, the point <code>x</code> in the data space, and the <code>decoder_output</code>.</li><li><code>position_logprior::Function</code>: The function to compute the log-prior of the latent space position. Default is <code>spherical_logprior</code>. This function must take as input the point <code>z</code> in the latent space.</li><li><code>momentum_logprior::Function</code>: The function to compute the log-prior of the momentum. Default is <code>riemannian_logprior</code>. This function must take as input the momentum <code>ρ</code> and <code>G⁻¹</code>.</li></ul><p><strong>Returns</strong></p><p>A matrix representing the gradient of the Hamiltonian at the point <code>(z, ρ)</code> with respect to variable <code>var</code>.</p><p><strong>Note</strong></p><p><code>ForwardDiff.jl</code> is not composable with <code>Zygote.jl.</code> Thus, for backpropagation using this function one should use <code>ReverseDiff.jl.</code></p></div></section><section><div><pre><code class="language-julia hljs">∇hamiltonian_ForwardDiff(
    x::AbstractArray,
    z::AbstractVecOrMat,
    ρ::AbstractVecOrMat,
    rhvae::RHVAE,
    var::Symbol;
    reconstruction_loglikelihood::Function=decoder_loglikelihood,
    position_logprior::Function=spherical_logprior,
    momentum_logprior::Function=riemannian_logprior,
    G_inv::Function=G_inv,
)</code></pre><p>Compute the gradient of the Hamiltonian with respect to a given variable using the ForwardDiff.jl automatic differentiation library.</p><p>This function takes a point <code>x</code> in the data space, a point <code>z</code> in the latent space, a momentum <code>ρ</code>, an instance of <code>RHVAE</code>, and a variable <code>var</code> (:z or :ρ), and computes the gradient of the Hamiltonian with respect to <code>var</code> using ForwardDiff.jl.</p><p>The Hamiltonian is computed as follows:</p><p>Hₓ(z, ρ) = Uₓ(z) + κ(ρ),</p><p>where Uₓ(z) is the potential energy, and κ(ρ) is the kinetic energy. The potential energy is defined as follows:</p><p>Uₓ(z) = -log p(x|z) - log p(z),</p><p>where p(x|z) is the log-likelihood of the decoder and p(z) is the log-prior in latent space. The kinetic energy is defined as follows:</p><p>κ(ρ) = 0.5 * log((2π)ᴰ det G(z)) + 0.5 * ρᵀ G⁻¹ ρ</p><p>where D is the dimension of the latent space, and G(z) is the metric tensor at the point <code>z</code>.</p><p><strong>Arguments</strong></p><ul><li><code>x::AbstractArray</code>: The point in the data space. This does not necessarily need to be a vector. Array inputs are supported. The last dimension is assumed to have each of the data points.</li><li><code>z::AbstractVecOrMat</code>: The point in the latent space. If matrix, each column represents a point in the latent space.</li><li><code>ρ::AbstractVecOrMat</code>: The momentum. If matrix, each column represents a momentum vector.</li><li><code>rhvae::RHVAE</code>: An instance of the RHVAE model.</li><li><code>var::Symbol</code>: The variable with respect to which the gradient is computed. Must be :z or :ρ.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>reconstruction_loglikelihood::Function</code>: The function to compute the log-likelihood of the decoder reconstruction. Default is <code>decoder_loglikelihood</code>. This function must take as input the decoder, the point <code>x</code> in the data space, and the <code>decoder_output</code>.</li><li><code>position_logprior::Function</code>: The function to compute the log-prior of the latent space position. Default is <code>spherical_logprior</code>. This function must take as input the point <code>z</code> in the latent space.</li><li><code>momentum_logprior::Function</code>: The function to compute the log-prior of the momentum. Default is <code>riemannian_logprior</code>. This function must take as input the momentum <code>ρ</code> and the inverse of the Riemannian metric tensor <code>G⁻¹</code>.</li><li><code>G_inv::Function</code>: The function to compute the inverse of the Riemannian metric tensor. Default is <code>G_inv</code>. This function must take as input the point <code>z</code> in the latent space and the <code>rhvae</code> instance.</li></ul><p><strong>Returns</strong></p><p>A matrix representing the gradient of the Hamiltonian at the point <code>(z, ρ)</code> with respect to variable <code>var</code>.</p><p><strong>Note</strong></p><p><code>ForwardDiff.jl</code> is not composable with <code>Zygote.jl.</code> Thus, for backpropagation using this function one should use <code>ReverseDiff.jl.</code></p></div></section></article><h2 id="Other-Functions"><a class="docs-heading-anchor" href="#Other-Functions">Other Functions</a><a id="Other-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Other-Functions" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AutoEncode.RHVAEs.update_metric" href="#AutoEncode.RHVAEs.update_metric"><code>AutoEncode.RHVAEs.update_metric</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">update_metric(
    rhvae::RHVAE{&lt;:VAE{&lt;:AbstractGaussianEncoder,&lt;:AbstractVariationalDecoder}}
)</code></pre><p>Compute the <code>centroids_latent</code> and <code>M</code> field of a <code>RHVAE</code> instance without modifying the instance. This method is used when needing to backpropagate through the RHVAE during training.</p><p><strong>Arguments</strong></p><ul><li><code>rhvae::RHVAE{&lt;:VAE{&lt;:AbstractGaussianEncoder,&lt;:AbstractVariationalDecoder}}</code>: The <code>RHVAE</code> instance to be updated.</li></ul><p><strong>Returns</strong></p><ul><li>NamedTuple with the following fields:<ul><li><code>centroids_latent::Matrix</code>: A matrix where each column represents a centroid cᵢ in the inverse metric computation.</li><li><code>L::Array{&lt;:Number, 3}</code>: A 3D array where each slice represents a L_ψᵢ matrix.</li><li><code>M::Array{&lt;:Number, 3}</code>: A 3D array where each slice represents a L<em>ψᵢ L</em>ψᵢᵀ.</li></ul></li></ul></div></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AutoEncode.RHVAEs.update_metric!" href="#AutoEncode.RHVAEs.update_metric!"><code>AutoEncode.RHVAEs.update_metric!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">update_metric!(
    rhvae::RHVAE{&lt;:VAE{&lt;:AbstractGaussianEncoder,&lt;:AbstractVariationalDecoder}},
    params::NamedTuple
)</code></pre><p>Update the <code>centroids_latent</code> and <code>M</code> fields of a <code>RHVAE</code> instance in place.</p><p>This function takes a <code>RHVAE</code> instance and a named tuple <code>params</code> containing the new values for <code>centroids_latent</code> and <code>M</code>. It updates the <code>centroids_latent</code>, <code>L</code>, and <code>M</code> fields of the <code>RHVAE</code> instance with the provided values.</p><p><strong>Arguments</strong></p><ul><li><code>rhvae::RHVAE{&lt;:VAE{&lt;:AbstractGaussianEncoder,&lt;:AbstractVariationalDecoder}}</code>: The <code>RHVAE</code> instance to update.</li><li><code>params::NamedTuple</code>: A named tuple containing the new values for <code>centroids_latent</code> and <code>M</code>. Must have the keys <code>:centroids_latent</code>, <code>:L</code>, and <code>:M</code>.</li></ul><p><strong>Returns</strong></p><p>Nothing. The <code>RHVAE</code> instance is updated in place.</p></div></section><section><div><pre><code class="language-julia hljs">update_metric!(
    rhvae::RHVAE{
        &lt;:VAE{&lt;:AbstractGaussianEncoder,&lt;:AbstractVariationalDecoder}
    }
)</code></pre><p>Update the <code>centroids_latent</code>, and <code>M</code> fields of a <code>RHVAE</code> instance in place.</p><p>This function takes a <code>RHVAE</code> instance as input and modifies its <code>centroids_latent</code> and <code>M</code> fields. The <code>centroids_latent</code> field is updated by running the <code>centroids_data</code> through the encoder of the underlying VAE and extracting the mean (µ) of the resulting Gaussian distribution. The <code>M</code> field is updated by running each column of the <code>centroids_data</code> through the <code>metric_chain</code> and concatenating the results along the third dimension, then each slice is updated by multiplying each slice of <code>L</code> by its transpose and concating the results along the third dimension.</p><p><strong>Arguments</strong></p><ul><li><code>rhvae::RHVAE{&lt;:VAE{&lt;:AbstractGaussianEncoder,&lt;:AbstractVariationalDecoder}}</code>: The <code>RHVAE</code> instance to be updated.</li></ul><p><strong>Notes</strong></p><p>This function modifies the <code>RHVAE</code> instance in place, so it does not return anything. The changes are made directly to the <code>centroids_latent</code>, <code>L</code>, and <code>M</code> fields of the input <code>RHVAE</code> instance.</p></div></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AutoEncode.RHVAEs.G_inv" href="#AutoEncode.RHVAEs.G_inv"><code>AutoEncode.RHVAEs.G_inv</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">G_inv(
    z::AbstractVecOrMat,
    centroids_latent::AbstractMatrix,
    M::AbstractArray{&lt;:Number,3},
    T::Number,
    λ::Number,
)</code></pre><p>Compute the inverse of the metric tensor G for a given point in the latent space.</p><p>This function takes a point <code>z</code> in the latent space, the <code>centroids_latent</code> of the RHVAE instance, a 3D array <code>M</code> representing the metric tensor, a temperature <code>T</code>, and a regularization factor <code>λ</code>, and computes the inverse of the metric tensor G at that point. The computation is based on the centroids and the temperature, as well as a regularization term. The inverse metric is computed as follows:</p><p>G⁻¹(z) = ∑ᵢ₌₁ⁿ L<em>ψᵢ L</em>ψᵢᵀ exp(-‖z - cᵢ‖₂² / T²) + λIₗ,</p><p>where L<em>ψᵢ is computed by the <code>MetricChain</code>, T is the temperature, λ is a regularization factor, and each column of `centroids</em>latent` are the cᵢ.</p><p><strong>Arguments</strong></p><ul><li><code>z::AbstractVecOrMat</code>: The point in the latent space. If a matrix, each column represents a point in the latent space.</li><li><code>centroids_latent::AbstractMatrix</code>: The centroids in the latent space.</li><li><code>M::AbstractArray{&lt;:Number,3}</code>: The 3D array containing the symmetric matrices used to compute the inverse metric tensor.</li><li><code>T::N</code>: The temperature.</li><li><code>λ::N</code>: The regularization factor.</li></ul><p><strong>Returns</strong></p><p>A matrix or 3D array representing the inverse of the metric tensor G at the point <code>z</code>. If a 3D array, each slice represents the inverse metric tensor at a different point in the latent space.</p><p><strong>Notes</strong></p><p>The computation involves the squared Euclidean distance between z and each centroid, the exponential of the negative of these distances divided by the square of the temperature, and a regularization term proportional to the identity matrix. The result is a matrix of the same size as the latent space.</p><p><strong>GPU support</strong></p><p>This function supports CPU and GPU arrays.</p></div></section><section><div><pre><code class="language-julia hljs">G_inv( 
    z::AbstractVecOrMat,
    metric_param::Union{RHVAE,NamedTuple},
)</code></pre><p>Compute the inverse of the metric tensor G for a given point in the latent space.</p><p>This function takes a <code>RHVAE</code> instance and a point <code>z</code> in the latent space, and computes the inverse of the metric tensor G at that point. The computation is based on the centroids and the temperature of the <code>RHVAE</code> instance, as well as a regularization term. The inverse metric is computed as follows:</p><p>G⁻¹(z) = ∑ᵢ₌₁ⁿ L<em>ψᵢ L</em>ψᵢᵀ exp(-‖z - cᵢ‖₂² / T²) + λIₗ,</p><p>where L<em>ψᵢ is computed by the <code>MetricChain</code>, T is the temperature, λ is a regularization factor, and each column of `centroids</em>latent` are the cᵢ.</p><p><strong>Arguments</strong></p><ul><li><code>z::AbstractVecOrMat</code>: The point in the latent space. If a matrix, each column represents a point in the latent space.</li><li><code>metric_param::Union{RHVAE,NamedTuple}</code>: Either an <code>RHVAE</code> instance or a named tuple containing the fields <code>centroids_latent</code>, <code>M</code>, <code>T</code>, and <code>λ</code>.</li></ul><p><strong>Returns</strong></p><p>A matrix representing the inverse of the metric tensor G at the point <code>z</code>.</p><p><strong>Notes</strong></p><p>The computation involves the squared Euclidean distance between z and each centroid of the RHVAE instance, the exponential of the negative of these distances divided by the square of the temperature, and a regularization term proportional to the identity matrix. The result is a matrix of the same size as the latent space.</p></div></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AutoEncode.RHVAEs.metric_tensor" href="#AutoEncode.RHVAEs.metric_tensor"><code>AutoEncode.RHVAEs.metric_tensor</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">metric_tensor(
    z::AbstractVecOrMat,
    metric_param::Union{RHVAE,NamedTuple},
)</code></pre><p>Compute the metric tensor G for a given point in the latent space. This function is a wrapper that determines the type of the input <code>z</code> and calls the appropriate specialized function <code>_metric_tensor</code> to perform the actual computation.</p><p>This function takes a <code>RHVAE</code> instance or a named tuple containing the fields <code>centroids_latent</code>, <code>M</code>, <code>T</code>, and <code>λ</code>, and a point <code>z</code> in the latent space, and computes the metric tensor G at that point. The computation is based on the inverse of the metric tensor G, which is computed by the <code>G_inv</code> function.</p><p><strong>Arguments</strong></p><ul><li><code>z::AbstractVecOrMat</code>: The point in the latent space. If a matrix, each column represents a point in the latent space.</li><li><code>metric_param::Union{RHVAE,NamedTuple}</code>: Either an <code>RHVAE</code> instance or a named tuple containing the fields <code>centroids_latent</code>, <code>M</code>, <code>T</code>, and <code>λ</code>.</li></ul><p><strong>Returns</strong></p><p>A matrix representing the metric tensor G at the point <code>z</code>.</p><p><strong>Notes</strong></p><p>The computation involves the inverse of the metric tensor G at the point z. The result is a matrix of the same size as the latent space.</p><p><strong>GPU Support</strong></p><p>This function supports CPU and GPU arrays.</p></div></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AutoEncode.RHVAEs.riemannian_logprior" href="#AutoEncode.RHVAEs.riemannian_logprior"><code>AutoEncode.RHVAEs.riemannian_logprior</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">riemannian_logprior(
    ρ::AbstractVector,
    G⁻¹::AbstractMatrix,
    logdetG::Number;
)</code></pre><p>CPU AbstractVector version of the riemannian_logprior function.</p></div></section><section><div><pre><code class="language-julia hljs">riemannian_logprior(
    ρ::AbstractVector,
    G⁻¹::AbstractMatrix,
    logdetG::Number,
)</code></pre><p>CPU AbstractMatrix version of the riemannian_logprior function.</p></div></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AutoEncode.RHVAEs.hamiltonian" href="#AutoEncode.RHVAEs.hamiltonian"><code>AutoEncode.RHVAEs.hamiltonian</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">hamiltonian(
    x::AbstractArray,
    z::AbstractVecOrMat,
    ρ::AbstractVecOrMat,
    G⁻¹::AbstractArray,
    logdetG::Union{&lt;:Number,&lt;:AbstractVector},
    decoder::AbstractVariationalDecoder,
    decoder_output::NamedTuple;
    decoder_loglikelihood::Function=decoder_loglikelihood,
    position_logprior::Function=spherical_logprior,
    momentum_logprior::Function=riemannian_logprior,
)</code></pre><p>Compute the Hamiltonian for a given point in the latent space and a given momentum.</p><p>This function takes a point <code>x</code> in the data space, a point <code>z</code> in the latent space, a momentum <code>ρ</code>, the inverse of the Riemannian metric tensor <code>G⁻¹</code>, a <code>decoder</code> of type <code>AbstractVariationalDecoder</code>, and a <code>decoder_output</code> NamedTuple, and computes the Hamiltonian. The computation is based on the log-likelihood of the decoder, the log-prior of the latent space, and the inverse of the metric tensor G at the point <code>z</code>.</p><p>The Hamiltonian is computed as follows:</p><p>Hₓ(z, ρ) = Uₓ(z) + κ(ρ),</p><p>where Uₓ(z) is the potential energy, and κ(ρ) is the kinetic energy. The potential energy is defined as follows:</p><p>Uₓ(z) = -log p(x|z) - log p(z),</p><p>where p(x|z) is the log-likelihood of the decoder and p(z) is the log-prior in latent space. The kinetic energy is defined as follows:</p><p>κ(ρ) = -log p(ρ),</p><p>where p(ρ) is the log-prior of the momentum.</p><p><strong>Arguments</strong></p><ul><li><code>x::AbstractArray</code>: The point in the data space. This does not necessarily need to be a vector. Array inputs are supported, but the last dimension of the array should be of size 1.</li><li><code>z::AbstractVecOrMat</code>: The point in the latent space.</li><li><code>ρ::AbstractVecOrMat</code>: The momentum.</li><li><code>G⁻¹::AbstractArray</code>: The inverse of the Riemannian metric tensor. This should be computed elsewhere and should correspond to the given <code>z</code> value.</li><li><code>logdetG::Union{&lt;:Number,AbstractVector}</code>: The log determinant of the Riemannian metric tensor. This should be computed elsewhere and should correspond to the given <code>z</code> value.</li><li><code>decoder::AbstractVariationalDecoder</code>: The decoder instance. This is not used in the computation of the Hamiltonian, but is passed to the <code>decoder_loglikelihood</code> function to know which method to use.</li><li><code>decoder_output::NamedTuple</code>: The output of the decoder.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>reconstruction_loglikelihood::Function</code>: The function to compute the log-likelihood of the decoder reconstruction. Default is <code>decoder_loglikelihood</code>. This function must take as input the decoder, the point <code>x</code> in the data space, and the <code>decoder_output</code>.</li><li><code>position_logprior::Function</code>: The function to compute the log-prior of the latent space position. Default is <code>spherical_logprior</code>. This function must take as input the point <code>z</code> in the latent space.</li><li><code>momentum_logprior::Function</code>: The function to compute the log-prior of the momentum. Default is <code>riemannian_logprior</code>. This function must take as input the momentum <code>ρ</code> and the inverse of the Riemannian metric tensor <code>G⁻¹</code>.</li></ul><p><strong>Returns</strong></p><p>A scalar representing the Hamiltonian at the point <code>z</code> with the momentum <code>ρ</code>.</p><p><strong>Note</strong></p><p>The inverse of the Riemannian metric tensor <code>G⁻¹</code> is assumed to be computed elsewhere. The user must ensure that the provided <code>G⁻¹</code> corresponds to the given <code>z</code> value.</p></div></section><section><div><pre><code class="language-julia hljs">hamiltonian(
    x::AbstractArray,
    z::AbstractVecOrMat,
    ρ::AbstractVecOrMat,
    rhvae::RHVAE;
    reconstruction_loglikelihood::Function=decoder_loglikelihood,
    position_logprior::Function=spherical_logprior,
    momentum_logprior::Function=riemannian_logprior,
    G_inv::Function=G_inv,
)</code></pre><p>Compute the Hamiltonian for a given point in the latent space and a given momentum.</p><p>This function takes a point <code>x</code> in the data space, a point <code>z</code> in the latent space, a momentum <code>ρ</code>, and an instance of <code>RHVAE</code>. It computes the inverse of the Riemannian metric tensor <code>G⁻¹</code> and the output of the decoder internally, and then computes the Hamiltonian. The computation is based on the log-likelihood of the decoder, the log-prior of the latent space, and the inverse of the metric tensor G at the point <code>z</code>.</p><p>The Hamiltonian is computed as follows:</p><p>Hₓ(z, ρ) = Uₓ(z) + κ(ρ),</p><p>where Uₓ(z) is the potential energy, and κ(ρ) is the kinetic energy. The potential energy is defined as follows:</p><p>Uₓ(z) = -log p(x|z) - log p(z),</p><p>where p(x|z) is the log-likelihood of the decoder and p(z) is the log-prior in latent space. The kinetic energy is defined as follows:</p><p>κ(ρ) = -log p(ρ),</p><p>where p(ρ) is the log-prior of the momentum.</p><p><strong>Arguments</strong></p><ul><li><code>x::AbstractArray</code>: The point in the data space. This does not necessarily need to be a vector. Array inputs are supported, but the last dimension of the array should be of size 1.</li><li><code>z::AbstractVector</code>: The point in the latent space.</li><li><code>ρ::AbstractVector</code>: The momentum.</li><li><code>rhvae::RHVAE</code>: An instance of the RHVAE model.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>reconstruction_loglikelihood::Function</code>: The function to compute the log-likelihood of the decoder reconstruction. Default is <code>decoder_loglikelihood</code>. This function must take as input the decoder, the point <code>x</code> in the data space, and the <code>decoder_output</code>.</li><li><code>position_logprior::Function</code>: The function to compute the log-prior of the latent space position. Default is <code>spherical_logprior</code>. This function must take as input the point <code>z</code> in the latent space.</li><li><code>momentum_logprior::Function</code>: The function to compute the log-prior of the momentum. Default is <code>riemannian_logprior</code>. This function must take as input the momentum <code>ρ</code> and the inverse of the Riemannian metric tensor <code>G⁻¹</code>.</li><li><code>G_inv::Function</code>: The function to compute the inverse of the Riemannian metric tensor. Default is <code>G_inv</code>. This function must take as input the point <code>z</code> in the latent space and the <code>rhvae</code> instance.</li></ul><p><strong>Returns</strong></p><p>A scalar representing the Hamiltonian at the point <code>z</code> with the momentum <code>ρ</code>.</p><p><strong>Note</strong></p><p>The inverse of the Riemannian metric tensor <code>G⁻¹</code>, the log determinant of the metric tensor, and the output of the decoder are computed internally in this function. The user does not need to provide these as inputs.</p></div></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AutoEncode.RHVAEs.∇hamiltonian" href="#AutoEncode.RHVAEs.∇hamiltonian"><code>AutoEncode.RHVAEs.∇hamiltonian</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">∇hamiltonian(
    x::AbstractArray,
    z::AbstractVecOrMat,
    ρ::AbstractVecOrMat,
    G⁻¹::AbstractArray,
    logdetG::Union{&lt;:Number,AbstractVector},
    decoder::AbstractVariationalDecoder,
    decoder_output::NamedTuple,
    var::Symbol;
    reconstruction_loglikelihood::Function=decoder_loglikelihood,
    position_logprior::Function=spherical_logprior,
    momentum_logprior::Function=riemannian_logprior,
    adtype::Symbol=:TaylorDiff,
    adkwargs::Union{NamedTuple,Dict}=Dict(),
)</code></pre><p>Compute the gradient of the Hamiltonian with respect to a given variable using a specified automatic differentiation method.</p><p>This function takes a point <code>x</code> in the data space, a point <code>z</code> in the latent space, a momentum <code>ρ</code>, the inverse of the Riemannian metric tensor <code>G⁻¹</code>, a <code>decoder</code> of type <code>AbstractVariationalDecoder</code>, a <code>decoder_output</code> NamedTuple, and a variable <code>var</code> (:z or :ρ), and computes the gradient of the Hamiltonian with respect to <code>var</code> using the specified automatic differentiation method. The computation is based on the log-likelihood of the decoder, the log-prior of the latent space, and <code>G⁻¹</code>.</p><p>The Hamiltonian is computed as follows:</p><p>Hₓ(z, ρ) = Uₓ(z) + κ(ρ),</p><p>where Uₓ(z) is the potential energy, and κ(ρ) is the kinetic energy. The potential energy is defined as follows:</p><p>Uₓ(z) = -log p(x|z) - log p(z),</p><p>where p(x|z) is the log-likelihood of the decoder and p(z) is the log-prior in latent space. The kinetic energy is defined as follows:</p><p>κ(ρ) = 0.5 * log((2π)ᴰ det G(z)) + 0.5 * ρᵀ G⁻¹ ρ</p><p>where D is the dimension of the latent space, and G(z) is the metric tensor at the point <code>z</code>.</p><p><strong>Arguments</strong></p><ul><li><code>x::AbstractArray</code>: The point in the data space. This does not necessarily need to be a vector. Array inputs are supported. The last dimension is assumed to have each of the data points.</li><li><code>z::AbstractVecOrMat</code>: The point in the latent space. If matrix, each column represents a point in the latent space.</li><li><code>ρ::AbstractVecOrMat</code>: The momentum. If matrix, each column represents a momentum vector.</li><li><code>G⁻¹::AbstractArray</code>: The inverse of the Riemannian metric tensor.  If 3D array, each slice along the third dimension represents the inverse of the metric tensor at the corresponding column of <code>z</code>.</li><li><code>logdetG::Union{&lt;:Number,AbstractVector}</code>: The log determinant of the Riemannian metric tensor. If vector, each element represents the log determinant of the metric tensor at the corresponding column of <code>z</code>.</li><li><code>decoder::AbstractVariationalDecoder</code>: The decoder instance.</li><li><code>decoder_output::NamedTuple</code>: The output of the decoder.</li><li><code>var::Symbol</code>: The variable with respect to which the gradient is computed. Must be :z or :ρ.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>reconstruction_loglikelihood::Function</code>: The function to compute the log-likelihood of the decoder reconstruction. Default is <code>decoder_loglikelihood</code>. This function must take as input the decoder, the point <code>x</code> in the data space, and the <code>decoder_output</code>.</li><li><code>position_logprior::Function</code>: The function to compute the log-prior of the latent space position. Default is <code>spherical_logprior</code>. This function must take as input the point <code>z</code> in the latent space.</li><li><code>momentum_logprior::Function</code>: The function to compute the log-prior of the momentum. Default is <code>riemannian_logprior</code>. This function must take as input the momentum <code>ρ</code> and <code>G⁻¹</code>.</li><li><code>adtype::Union{Symbol,Nothing}</code>=:TaylorDiff<code>: The type of automatic differentiation method to use. Must be :finite, :ForwardDiff, :TaylorDiff, or</code>nothing`. Default is nothing, therefore, for GPU arrays, finite differences are used, and for CPU arrays, TaylorDiff is used.</li><li><code>adkwargs::Union{NamedTuple,Dict}=Dict()</code>: Additional keyword arguments to pass to the automatic differentiation method.</li></ul><p><strong>Returns</strong></p><p>A vector representing the gradient of the Hamiltonian at the point <code>(z, ρ)</code> with respect to variable <code>var</code>.</p></div></section><section><div><pre><code class="language-julia hljs">∇hamiltonian(
    x::AbstractArray,
    z::AbstractVecOrMat,
    ρ::AbstractVecOrMat,
    rhvae::RHVAE,
    var::Symbol;
    reconstruction_loglikelihood::Function=decoder_loglikelihood,
    position_logprior::Function=spherical_logprior,
    momentum_logprior::Function=riemannian_logprior,
    G_inv::Function=G_inv,
    adtype::Symbol=:TaylorDiff,
    adkwargs::Union{NamedTuple,Dict}=Dict(),
)</code></pre><p>Compute the gradient of the Hamiltonian with respect to a given variable using a specified automatic differentiation method.</p><p>This function takes a point <code>x</code> in the data space, a point <code>z</code> in the latent space, a momentum <code>ρ</code>, an instance of <code>RHVAE</code>, and a variable <code>var</code> (:z or :ρ), and computes the gradient of the Hamiltonian with respect to <code>var</code> using the specified automatic differentiation method. The computation is based on the log-likelihood of the decoder, the log-prior of the latent space, and <code>G_inv</code>.</p><p><strong>Arguments</strong></p><ul><li><code>x::AbstractArray</code>: The point in the data space. This does not necessarily need to be a vector. Array inputs are supported. The last dimension is assumed to have each of the data points.</li><li><code>z::AbstractVecOrMat</code>: The point in the latent space. If matrix, each column represents a point in the latent space.</li><li><code>ρ::AbstractVecOrMat</code>: The momentum. If matrix, each column represents a momentum vector.</li><li><code>rhvae::RHVAE</code>: An instance of the RHVAE model.</li><li><code>var::Symbol</code>: The variable with respect to which the gradient is computed. Must be :z or :ρ.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>reconstruction_loglikelihood::Function</code>: The function to compute the log-likelihood of the decoder reconstruction. Default is <code>decoder_loglikelihood</code>. This function must take as input the decoder, the point <code>x</code> in the data space, and the <code>decoder_output</code>.</li><li><code>position_logprior::Function</code>: The function to compute the log-prior of the latent space position. Default is <code>spherical_logprior</code>. This function must take as input the point <code>z</code> in the latent space.</li><li><code>momentum_logprior::Function</code>: The function to compute the log-prior of the momentum. Default is <code>riemannian_logprior</code>. This function must take as input the momentum <code>ρ</code> and <code>G_inv</code>.</li><li><code>G_inv::Function</code>: The function to compute the inverse of the Riemannian metric tensor.  Default is <code>G_inv</code>.</li><li><code>adtype::Union{Symbol,Nothing}</code>=:TaylorDiff<code>: The type of automatic differentiation method to use. Must be :finite, :ForwardDiff, :TaylorDiff, or</code>nothing`. Default is nothing, therefore, for GPU arrays, finite differences are used, and for CPU arrays, TaylorDiff is used.</li><li><code>adkwargs::Union{NamedTuple,Dict}=Dict()</code>: Additional keyword arguments to pass to the automatic differentiation method.</li></ul><p><strong>Returns</strong></p><p>A vector representing the gradient of the Hamiltonian at the point <code>(z, ρ)</code> with respect to variable <code>var</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AutoEncode.RHVAEs._leapfrog_first_step" href="#AutoEncode.RHVAEs._leapfrog_first_step"><code>AutoEncode.RHVAEs._leapfrog_first_step</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">_leapfrog_first_step(
    x::AbstractArray,
    z::AbstractVecOrMat,
    ρ::AbstractVecOrMat,
    G⁻¹::AbstractArray,
    logdetG::Union{&lt;:Number,AbstractVector},
    decoder::AbstractVariationalDecoder,
    decoder_output::NamedTuple;
    ϵ::Union{&lt;:Number,&lt;:AbstractVector}=Float32(1E-4),
    steps::Int=3,
    ∇H_kwargs::Union{NamedTuple,Dict}=(
        reconstruction_loglikelihood=decoder_loglikelihood,
        position_logprior=spherical_logprior,
        momentum_logprior=riemannian_logprior,
    ),
)</code></pre><p>Perform the first step of the generalized leapfrog integrator for Hamiltonian dynamics, defined as</p><p>ρ(t + ϵ/2) = ρ(t) - 0.5 * ϵ * ∇z_H(z(t), ρ(t + ϵ/2)).</p><p>This function is part of the generalized leapfrog integrator used in Hamiltonian dynamics. Unlike the standard leapfrog integrator, the generalized leapfrog integrator is implicit, which means it requires the use of fixed-point iterations to be solved.</p><p>The function takes a point <code>x</code> in the data space, a point <code>z</code> in the latent space, a momentum <code>ρ</code>, the inverse of the Riemannian metric tensor <code>G⁻¹</code>, a <code>decoder</code> of type <code>AbstractVariationalDecoder</code>, the output of the decoder <code>decoder_output</code>, a step size <code>ϵ</code>, and optionally the number of fixed-point iterations to perform (<code>steps</code>), a function to compute the gradient of the Hamiltonian (<code>∇H</code>), and a set of keyword arguments for <code>∇H</code> (<code>∇H_kwargs</code>).</p><p>The function performs the following update for <code>steps</code> times:</p><p>ρ̃ = ρ̃ - 0.5 * ϵ * ∇hamiltonian(x, z, ρ̃, G⁻¹, decoder, decoder<em>output, :z; ∇H</em>kwargs...)</p><p>where <code>∇H</code> is the gradient of the Hamiltonian with respect to the position variables <code>z</code>. The result is returned as ρ̃.</p><p><strong>Arguments</strong></p><ul><li><code>x::AbstractArray</code>: The point in the data space. This does not necessarily need to be a vector. Array inputs are supported. The last dimension is assumed to have each of the data points.</li><li><code>z::AbstractVecOrMat</code>: The point in the latent space. If matrix, each column represents a point in the latent space.</li><li><code>ρ::AbstractVecOrMat</code>: The momentum. If matrux, each column represents a momentum vector.</li><li><code>G⁻¹::AbstractArray</code>: The inverse of the Riemannian metric tensor. If 3D array, each slice along the third dimension represents the inverse of the metric tensor at the corresponding column of <code>z</code>.</li><li><code>logdetG::Union{&lt;:Number,AbstractVector}</code>: The log determinant of the Riemannian metric tensor. If vector, each element represents the log determinant of the metric tensor at the corresponding column of <code>z</code>.</li><li><code>decoder::AbstractVariationalDecoder</code>: The decoder instance.</li><li><code>decoder_output::NamedTuple</code>: The output of the decoder.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>ϵ::Union{&lt;:Number,&lt;:AbstractVector}=0.01f0</code>: The leapfrog step size. Default is 0.01f0.</li><li><code>steps::Int=3</code>: The number of fixed-point iterations to perform. Default is 3.</li><li><code>∇H_kwargs::Union{NamedTuple,Dict}</code>: The keyword arguments for <code>∇hamiltonian</code>. Default is a tuple with <code>reconstruction_loglikelihood</code>, <code>position_logprior</code>, <code>momentum_logprior</code>, and <code>G_inv</code>.</li></ul><p><strong>Returns</strong></p><p>A vector representing the updated momentum after performing the first step of the generalized leapfrog integrator.</p></div></section><section><div><pre><code class="language-julia hljs">_leapfrog_first_step(
    x::AbstractArray,
    z::AbstractVecOrMat,
    ρ::AbstractVecOrMat,
    rhvae::RHVAE;
    ϵ::Union{&lt;:Number,&lt;:AbstractVector}=Float32(1E-4),
    steps::Int=3,
    ∇H_kwargs::Union{NamedTuple,Dict}=(
        reconstruction_loglikelihood=decoder_loglikelihood,
        position_logprior=spherical_logprior,
        momentum_logprior=riemannian_logprior,
    ),
    G_inv::Function=G_inv,
)</code></pre><p>Perform the first step of the generalized leapfrog integrator for Hamiltonian dynamics, defined as</p><p>ρ(t + ϵ/2) = ρ(t) - 0.5 * ϵ * ∇z_H(z(t), ρ(t + ϵ/2)).</p><p>This function is part of the generalized leapfrog integrator used in Hamiltonian dynamics. Unlike the standard leapfrog integrator, the generalized leapfrog integrator is implicit, which means it requires the use of fixed-point iterations to be solved.</p><p>The function takes a <code>RHVAE</code> instance, a point <code>x</code> in the data space, a point <code>z</code> in the latent space, a momentum <code>ρ</code>, a step size <code>ϵ</code>, and optionally the number of fixed-point iterations to perform (<code>steps</code>), a function to compute the gradient of the Hamiltonian (<code>∇H</code>), and a set of keyword arguments for <code>∇H</code> (<code>∇H_kwargs</code>).</p><p>The function performs the following update for <code>steps</code> times:</p><p>ρ̃ = ρ̃ - 0.5 * ϵ * ∇hamiltonian(rhvae, x, z, ρ̃, :z; ∇H_kwargs...)</p><p>where <code>∇H</code> is the gradient of the Hamiltonian with respect to the position variables <code>z</code>. The result is returned as ρ̃.</p><p><strong>Arguments</strong></p><ul><li><code>x::AbstractArray</code>: The point in the data space. This does not necessarily need to be a vector. Array inputs are supported. The last dimension is assumed to have each of the data points.</li><li><code>z::AbstractVecOrMat</code>: The point in the latent space. If matrix, each column represents a point in the latent space.</li><li><code>ρ::AbstractVecOrMat</code>: The momentum. If matrux, each column represents a momentum vector.</li><li><code>rhvae::RHVAE</code>: The <code>RHVAE</code> instance.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>ϵ::Union{&lt;:Number,&lt;:AbstractVector}=0.01f0</code>: The leapfrog step size. Default is 0.01f0.</li><li><code>steps::Int=3</code>: The number of fixed-point iterations to perform. Default is 3.</li><li><code>∇H_kwargs::Union{NamedTuple,Dict}</code>: The keyword arguments for <code>∇hamiltonian</code>. Default is a tuple with <code>reconstruction_loglikelihood</code>, <code>position_logprior</code>, and <code>momentum_logprior</code>.</li><li><code>G_inv::Function</code>: The function to compute the inverse of the Riemannian metric tensor. Default is <code>G_inv</code>.</li></ul><p><strong>Returns</strong></p><p>A vector representing the updated momentum after performing the first step of the generalized leapfrog integrator.</p></div></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AutoEncode.RHVAEs._leapfrog_second_step" href="#AutoEncode.RHVAEs._leapfrog_second_step"><code>AutoEncode.RHVAEs._leapfrog_second_step</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">_leapfrog_second_step(
    x::AbstractArray,
    z::AbstractVecOrMat,
    ρ::AbstractVecOrMat,
    G⁻¹::AbstractArray,
    logdetG::Union{&lt;:Number,AbstractVector},
    decoder::AbstractVariationalDecoder,
    decoder_output::NamedTuple;
    ϵ::Union{&lt;:Number,&lt;:AbstractVector}=Float32(1E-4),
    steps::Int=3,
    ∇H_kwargs::Union{NamedTuple,Dict}=(
            reconstruction_loglikelihood=decoder_loglikelihood,
            position_logprior=spherical_logprior,
            momentum_logprior=riemannian_logprior,
    ),
)</code></pre><p>Perform the second step of the generalized leapfrog integrator for Hamiltonian dynamics, defined as</p><p>z(t + ϵ) = z(t) + 0.5 * ϵ * [∇ρ<em>H(z(t), ρ(t+ϵ/2)) + ∇ρ</em>H(z(t + ϵ), ρ(t+ϵ/2))].</p><p>This function is part of the generalized leapfrog integrator used in Hamiltonian dynamics. Unlike the standard leapfrog integrator, the generalized leapfrog integrator is implicit, which means it requires the use of fixed-point iterations to be solved.</p><p>The function takes a point <code>x</code> in the data space, a point <code>z</code> in the latent space, a momentum <code>ρ</code>, the inverse of the Riemannian metric tensor <code>G⁻¹</code>, a <code>decoder</code> of type <code>AbstractVariationalDecoder</code>, the output of the decoder <code>decoder_output</code>, a step size <code>ϵ</code>, and optionally the number of fixed-point iterations to perform (<code>steps</code>), a function to compute the gradient of the Hamiltonian (<code>∇H</code>), and a set of keyword arguments for <code>∇H</code> (<code>∇H_kwargs</code>).</p><p>The function performs the following update for <code>steps</code> times:</p><p>z̄ = z̄ + 0.5 * ϵ * (      ∇hamiltonian(x, z̄, ρ, G⁻¹, decoder, decoder<em>output, :ρ; ∇H</em>kwargs...) +      ∇hamiltonian(x, z, ρ, G⁻¹, decoder, decoder<em>output, :ρ; ∇H</em>kwargs...)  )</p><p>where <code>∇H</code> is the gradient of the Hamiltonian with respect to the momentum variables <code>ρ</code>. The result is returned as z̄.</p><p><strong>Arguments</strong></p><ul><li><code>x::AbstractArray</code>: The point in the data space. This does not necessarily need to be a vector. Array inputs are supported. The last dimension is assumed to have each of the data points.</li><li><code>z::AbstractVecOrMat</code>: The point in the latent space. If matrix, each column represents a point in the latent space.</li><li><code>ρ::AbstractVecOrMat</code>: The momentum. If matrux, each column represents a momentum vector.</li><li><code>G⁻¹::AbstractArray</code>: The inverse of the Riemannian metric tensor. If 3D array, each slice along the third dimension represents the inverse of the metric tensor at the corresponding column of <code>z</code>.</li><li><code>logdetG::Union{&lt;:Number,AbstractVector}</code>: The log determinant of the Riemannian metric tensor. If vector, each element represents the log determinant of the metric tensor at the corresponding column of <code>z</code>.</li><li><code>decoder::AbstractVariationalDecoder</code>: The decoder instance.</li><li><code>decoder_output::NamedTuple</code>: The output of the decoder.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>ϵ::Union{&lt;:Number,&lt;:AbstractVector}=0.01f0</code>: The step size. Default is 0.01.</li><li><code>steps::Int=3</code>: The number of fixed-point iterations to perform. Default is 3.</li><li><code>∇H_kwargs::Union{NamedTuple,Dict}</code>: The keyword arguments for <code>∇hamiltonian</code>. Default is a tuple with <code>reconstruction_loglikelihood</code>, <code>position_logprior</code>, <code>momentum_logprior</code>.</li></ul><p><strong>Returns</strong></p><p>A vector representing the updated position after performing the second step of the generalized leapfrog integrator.</p></div></section><section><div><pre><code class="language-julia hljs">_leapfrog_second_step(
    x::AbstractArray,
    z::AbstractVecOrMat,
    ρ::AbstractVecOrMat,
    rhvae::RHVAE;
    ϵ::Union{&lt;:Number,&lt;:AbstractVector}=Float32(1E-4),
    steps::Int=3,
    ∇H_kwargs::Union{NamedTuple,Dict}=(
            reconstruction_loglikelihood=decoder_loglikelihood,
            position_logprior=spherical_logprior,
            momentum_logprior=riemannian_logprior,
    ),
    G_inv::Function=G_inv,
)</code></pre><p>Perform the second step of the generalized leapfrog integrator for Hamiltonian dynamics, defined as</p><p>z(t + ϵ) = z(t) + 0.5 * ϵ * [∇ρ<em>H(z(t), ρ(t+ϵ/2)) + ∇ρ</em>H(z(t + ϵ), ρ(t+ϵ/2))].</p><p>This function is part of the generalized leapfrog integrator used in Hamiltonian dynamics. Unlike the standard leapfrog integrator, the generalized leapfrog integrator is implicit, which means it requires the use of fixed-point iterations to be solved.</p><p>The function takes a <code>RHVAE</code> instance, a point <code>x</code> in the data space, a point <code>z</code> in the latent space, a momentum <code>ρ</code>, a step size <code>ϵ</code>, and optionally the number of fixed-point iterations to perform (<code>steps</code>), a function to compute the gradient of the Hamiltonian (<code>∇H</code>), and a set of keyword arguments for <code>∇H</code> (<code>∇H_kwargs</code>).</p><p>The function performs the following update for <code>steps</code> times:</p><p>z̄ = z̄ + 0.5 * ϵ * ( ∇hamiltonian(rhvae, x, z̄, ρ, :ρ; ∇H<em>kwargs...) +         ∇hamiltonian(rhvae, x, z, ρ, :ρ; ∇H</em>kwargs...) )</p><p>where <code>∇H</code> is the gradient of the Hamiltonian with respect to the momentum variables <code>ρ</code>. The result is returned as z̄.</p><p><strong>Arguments</strong></p><ul><li><code>x::AbstractArray</code>: The point in the data space. This does not necessarily need to be a vector. Array inputs are supported. The last dimension is assumed to have each of the data points.</li><li><code>z::AbstractVecOrMat</code>: The point in the latent space. If matrix, each column represents a point in the latent space.</li><li><code>ρ::AbstractVecOrMat</code>: The momentum. If matrux, each column represents a momentum vector.</li><li><code>rhvae::RHVAE</code>: The <code>RHVAE</code> instance.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>ϵ::Union{&lt;:Number,&lt;:AbstractVector}=0.01f0</code>: The leapfrog step size. Default is 0.01f0.</li><li><code>steps::Int=3</code>: The number of fixed-point iterations to perform. Default is 3. Typically, 3 iterations are sufficient.</li><li><code>∇H_kwargs::Union{NamedTuple,Dict}</code>: The keyword arguments for <code>∇hamiltonian</code>. Default is a tuple with <code>reconstruction_loglikelihood</code>, <code>position_logprior</code>, and <code>momentum_logprior</code>.</li><li><code>G_inv::Function</code>: The function to compute the inverse of the Riemannian metric tensor. Default is <code>G_inv</code>.</li></ul><p><strong>Returns</strong></p><p>A vector representing the updated position after performing the second step of the generalized leapfrog integrator.</p></div></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AutoEncode.RHVAEs._leapfrog_third_step" href="#AutoEncode.RHVAEs._leapfrog_third_step"><code>AutoEncode.RHVAEs._leapfrog_third_step</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">_leapfrog_third_step(
    x::AbstractArray,
    z::AbstractVecOrMat,
    ρ::AbstractVecOrMat,
    G⁻¹::AbstractArray,
    logdetG::Union{&lt;:Number,AbstractVector},
    decoder::AbstractVariationalDecoder,
    decoder_output::NamedTuple;
    ϵ::Union{&lt;:Number,&lt;:AbstractVector}=Float32(1E-4),
    ∇H_kwargs::Union{NamedTuple,Dict}=(
            reconstruction_loglikelihood=decoder_loglikelihood,
            position_logprior=spherical_logprior,
            momentum_logprior=riemannian_logprior,
    ),
)</code></pre><p>Perform the third step of the generalized leapfrog integrator for Hamiltonian dynamics, defined as</p><p>ρ(t + ϵ) = ρ(t + ϵ/2) - 0.5 * ϵ * ∇z_H(z(t + ϵ), ρ(t + ϵ/2)).</p><p>This function is part of the generalized leapfrog integrator used in Hamiltonian dynamics. Unlike the standard leapfrog integrator, the generalized leapfrog integrator is implicit, which means it requires the use of fixed-point iterations to be solved.</p><p>The function takes a point <code>x</code> in the data space, a point <code>z</code> in the latent space, a momentum <code>ρ</code>, the inverse of the Riemannian metric tensor <code>G⁻¹</code>, a <code>decoder</code> of type <code>AbstractVariationalDecoder</code>, the output of the decoder <code>decoder_output</code>, a step size <code>ϵ</code>, a function to compute the gradient of the Hamiltonian (<code>∇H</code>), and a set of keyword arguments for <code>∇H</code> (<code>∇H_kwargs</code>).</p><p>The function performs the following update:</p><p>ρ̃ = ρ - 0.5 * ϵ * ∇hamiltonian( x, z, ρ, G⁻¹, decoder, decoder<em>output, :z;     ∇H</em>kwargs... )</p><p>where <code>∇H</code> is the gradient of the Hamiltonian with respect to the position variables <code>z</code>. The result is returned as ρ̃.</p><p><strong>Arguments</strong></p><ul><li><code>x::AbstractArray</code>: The point in the data space. This does not necessarily need to be a vector. Array inputs are supported. The last dimension is assumed to have each of the data points.</li><li><code>z::AbstractVecOrMat</code>: The point in the latent space. If matrix, each column represents a point in the latent space.</li><li><code>ρ::AbstractVecOrMat</code>: The momentum. If matrux, each column represents a momentum vector.</li><li><code>G⁻¹::AbstractArray</code>: The inverse of the Riemannian metric tensor. If 3D array, each slice along the third dimension represents the inverse of the metric tensor at the corresponding column of <code>z</code>.</li><li><code>logdetG::Union{&lt;:Number,AbstractVector}</code>: The log determinant of the Riemannian metric tensor. If vector, each element represents the log determinant of the metric tensor at the corresponding column of <code>z</code>.</li><li><code>decoder::AbstractVariationalDecoder</code>: The decoder instance.</li><li><code>decoder_output::NamedTuple</code>: The output of the decoder.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>ϵ::Union{&lt;:Number,&lt;:AbstractVector}=0.01f0</code>: The step size. Default is 0.01f0.</li><li><code>∇H_kwargs::Union{NamedTuple,Dict}</code>: The keyword arguments for <code>∇hamiltonian</code>. Default is a tuple with <code>reconstruction_loglikelihood</code>, <code>position_logprior</code>, <code>momentum_logprior</code>.</li></ul><p><strong>Returns</strong></p><p>A vector representing the updated momentum after performing the third step of the generalized leapfrog integrator.</p></div></section><section><div><pre><code class="language-julia hljs">_leapfrog_third_step(
    x::AbstractArray,
    z::AbstractVecOrMat,
    ρ::AbstractVecOrMat,
    rhvae::RHVAE;
    ϵ::Union{&lt;:Number,&lt;:AbstractVector}=Float32(1E-4),
    steps::Int=3,
    ∇H_kwargs::Union{NamedTuple,Dict}=(
            reconstruction_loglikelihood=decoder_loglikelihood,
            position_logprior=spherical_logprior,
            momentum_logprior=riemannian_logprior,
    ),
    G_inv::Function=G_inv,
)</code></pre><p>Perform the third step of the generalized leapfrog integrator for Hamiltonian dynamics, defined as</p><p>ρ(t + ϵ) = ρ(t + ϵ/2) - 0.5 * ϵ * ∇z_H(z(t + ϵ), ρ(t + ϵ/2)).</p><p>This function is part of the generalized leapfrog integrator used in Hamiltonian dynamics. Unlike the standard leapfrog integrator, the generalized leapfrog integrator is implicit, which means it requires the use of fixed-point iterations to be solved.</p><p>The function takes a <code>RHVAE</code> instance, a point <code>x</code> in the data space, a point <code>z</code> in the latent space, a momentum <code>ρ</code>, a step size <code>ϵ</code>, the number of fixed-point iterations to perform (<code>steps</code>), a function to compute the gradient of the Hamiltonian (<code>∇H</code>), and a set of keyword arguments for <code>∇H</code> (<code>∇H_kwargs</code>).</p><p>The function performs the following update:</p><p>ρ̃ = ρ - 0.5 * ϵ * ∇hamiltonian(rhvae, x, z, ρ, :z; ∇H_kwargs...)</p><p>where <code>∇H</code> is the gradient of the Hamiltonian with respect to the position variables <code>z</code>. The result is returned as ρ̃.</p><p><strong>Arguments</strong></p><ul><li><code>x::AbstractArray</code>: The point in the data space. This does not necessarily need to be a vector. Array inputs are supported. The last dimension is assumed to have each of the data points.</li><li><code>z::AbstractVecOrMat</code>: The point in the latent space. If matrix, each column represents a point in the latent space.</li><li><code>ρ::AbstractVecOrMat</code>: The momentum. If matrux, each column represents a momentum vector.</li><li><code>rhvae::RHVAE</code>: The <code>RHVAE</code> instance.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>ϵ::Union{&lt;:Number,&lt;:AbstractVector}</code>: The leapfrog step size. Default is 0.01f0.</li><li><code>steps::Int=3</code>: The number of fixed-point iterations to perform. Default is 3.</li><li><code>∇H_kwargs::Union{NamedTuple,Dict}</code>: The keyword arguments for <code>∇hamiltonian</code>. Default is a tuple with <code>reconstruction_loglikelihood</code>, <code>position_logprior</code>, and <code>momentum_logprior</code>.</li><li><code>G_inv::Function</code>: The function to compute the inverse of the Riemannian metric tensor. Default is <code>G_inv</code>.</li></ul><p><strong>Returns</strong></p><p>A vector representing the updated momentum after performing the third step of the generalized leapfrog integrator.</p></div></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AutoEncode.RHVAEs.general_leapfrog_step" href="#AutoEncode.RHVAEs.general_leapfrog_step"><code>AutoEncode.RHVAEs.general_leapfrog_step</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">general_leapfrog_step(
    x::AbstractArray,
    z::AbstractVecOrMat,
    ρ::AbstractVecOrMat,
    G⁻¹::AbstractArray,
    logdetG::Union{&lt;:Number,AbstractVector},
    decoder::AbstractVariationalDecoder,
    decoder_output::NamedTuple,
    metric_param::NamedTuple;
    ϵ::Union{&lt;:Number,&lt;:AbstractVector}=Float32(1E-4),
    steps::Int=3,
    ∇H_kwargs::Union{NamedTuple,Dict}=(
            reconstruction_loglikelihood=decoder_loglikelihood,
            position_logprior=spherical_logprior,
            momentum_logprior=riemannian_logprior,
    ),
    G_inv::Function=G_inv,
)</code></pre><p>Perform a full step of the generalized leapfrog integrator for Hamiltonian dynamics.</p><p>The leapfrog integrator is a numerical integration scheme used to simulate Hamiltonian dynamics. It consists of three steps:</p><ol><li><p>Half update of the momentum variable: </p><p>ρ(t + ϵ/2) = ρ(t) - 0.5 * ϵ * ∇z_H(z(t), ρ(t + ϵ/2)).</p></li><li><p>Full update of the position variable: </p></li></ol><p>z(t + ϵ) = z(t) + 0.5 * ϵ * [∇ρ<em>H(z(t), ρ(t+ϵ/2)) + ∇ρ</em>H(z(t + ϵ), ρ(t+ϵ/2))].</p><ol><li><p>Half update of the momentum variable: </p><p>ρ(t + ϵ) = ρ(t + ϵ/2) - 0.5 * ϵ * ∇z_H(z(t + ϵ), ρ(t + ϵ/2)).</p></li></ol><p>This function performs these three steps in sequence, using the <code>_leapfrog_first_step</code>, <code>_leapfrog_second_step</code> and <code>_leapfrog_third_step</code> helper functions.</p><p><strong>Arguments</strong></p><ul><li><code>x::AbstractArray</code>: The point in the data space. This does not necessarily need to be a vector. Array inputs are supported. The last dimension is assumed to have each of the data points.</li><li><code>z::AbstractVecOrMat</code>: The point in the latent space. If matrix, each column represents a point in the latent space.</li><li><code>ρ::AbstractVecOrMat</code>: The momentum. If matrux, each column represents a momentum vector.</li><li><code>G⁻¹::AbstractArray</code>: The inverse of the Riemannian metric tensor. If 3D array, each slice along the third dimension represents the inverse of the metric tensor at the corresponding column of <code>z</code>.</li><li><code>logdetG::Union{&lt;:Number,AbstractVector}</code>: The log determinant of the Riemannian metric tensor. If vector, each element represents the log determinant of the metric tensor at the corresponding column of <code>z</code>.</li><li><code>decoder::AbstractVariationalDecoder</code>: The decoder instance.</li><li><code>decoder_output::NamedTuple</code>: The output of the decoder.</li><li><code>metric_param::NamedTuple</code>: The parameters for the metric tensor.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>ϵ::Union{&lt;:Number,&lt;:AbstractVector}=0.01f0</code>: The step size. Default is 0.01.</li><li><code>steps::Int=3</code>: The number of fixed-point iterations to perform. Default is 3. Typically, 3 iterations are sufficient.</li><li><code>∇H_kwargs::Union{NamedTuple,Dict}</code>: The keyword arguments for <code>∇hamiltonian</code>. Default is a tuple with <code>decoder_loglikelihood</code>, <code>position_logprior</code>, <code>momentum_logprior</code>, and <code>G_inv</code>.</li><li><code>G_inv::Function=G_inv</code>: The function to compute the inverse of the Riemannian metric tensor.</li></ul><p><strong>Returns</strong></p><p>A tuple <code>(z̄, ρ̄, Ḡ⁻¹, logdetḠ, decoder_update)</code> representing the updated position, momentum, the inverse of the updated Riemannian metric tensor, the log of the determinant of the metric tensor and the updated decoder outputs after performing the full leapfrog step.</p></div></section><section><div><pre><code class="language-julia hljs">general_leapfrog_step(
    x::AbstractArray,
    z::AbstractVecOrMat,
    ρ::AbstractVecOrMat,
    rhvae::RHVAE;
    ϵ::Union{&lt;:Number,&lt;:AbstractVector}=Float32(1E-4),
    steps::Int=3,
    ∇H_kwargs::Union{NamedTuple,Dict}=(
            reconstruction_loglikelihood=decoder_loglikelihood,
            position_logprior=spherical_logprior,
            momentum_logprior=riemannian_logprior,
            G_inv=G_inv,
    ),
)</code></pre><p>Perform a full step of the generalized leapfrog integrator for Hamiltonian dynamics.</p><p>The leapfrog integrator is a numerical integration scheme used to simulate Hamiltonian dynamics. It consists of three steps:</p><ol><li><p>Half update of the momentum variable: ρ(t + ϵ/2) = ρ(t) - 0.5 * ϵ *  ∇z_H(z(t), ρ(t + ϵ/2)).</p></li><li><p>Full update of the position variable: z(t + ϵ) = z(t) + 0.5 * ϵ * [∇ρ_H(z(t),</p></li></ol><p>ρ(t+ϵ/2)) + ∇ρ_H(z(t + ϵ), ρ(t+ϵ/2))].</p><ol><li>Half update of the momentum variable: ρ(t + ϵ) = ρ(t + ϵ/2) - 0.5 * ϵ *  ∇z_H(z(t + ϵ), ρ(t + ϵ/2)).</li></ol><p>This function performs these three steps in sequence, using the <code>_leapfrog_first_step</code> and <code>_leapfrog_second_step</code> helper functions.</p><p><strong>Arguments</strong></p><ul><li><code>x::AbstractArray</code>: The point in the data space. This does not necessarily need to be a vector. Array inputs are supported. The last dimension is assumed to have each of the data points.</li><li><code>z::AbstractVecOrMat</code>: The point in the latent space. If matrix, each column represents a point in the latent space.</li><li><code>ρ::AbstractVecOrMat</code>: The momentum. If matrux, each column represents a momentum vector.</li><li><code>rhvae::RHVAE</code>: The <code>RHVAE</code> instance.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><p><code>ϵ::Union{&lt;:Number,&lt;:AbstractVector}=0.01f0</code>: The leapfrog step size. Default is 0.01f0.</p></li><li><p><code>steps::Int=3</code>: The number of fixed-point iterations to perform. Default is 3. Typically, 3 iterations are sufficient.</p></li><li><p><code>∇H_kwargs::Union{NamedTuple,Dict}</code>: The keyword arguments for <code>∇hamiltonian</code>. Default is a tuple with <code>decoder_loglikelihood</code>, <code>position_logprior</code>, and <code>momentum_logprior</code></p></li><li><p><code>G_inv::Function</code>: The function to compute the inverse of the Riemannian metric tensor. Default is <code>G_inv</code>.</p><p>A tuple <code>(z̄, ρ̄, Ḡ⁻¹, logdetḠ, decoder_update)</code> representing the updated position, momentum, the inverse of the updated Riemannian metric tensor, the log of the determinant of the metric tensor, and the updated decoder outputs after performing the full leapfrog step.</p></li></ul></div></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AutoEncode.RHVAEs.general_leapfrog_tempering_step" href="#AutoEncode.RHVAEs.general_leapfrog_tempering_step"><code>AutoEncode.RHVAEs.general_leapfrog_tempering_step</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">general_leapfrog_tempering_step(
    x::AbstractArray,
    zₒ::AbstractVecOrMat,
    Gₒ⁻¹::AbstractArray,
    logdetGₒ::Union{&lt;:Number,AbstractVector},
    decoder::AbstractVariationalDecoder,
    decoder_output::NamedTuple,
    metric_param::NamedTuple;
    ϵ::Union{&lt;:Number,&lt;:AbstractVector}=Float32(1E-4),
    K::Int=3,
    βₒ::Number=0.3f0,
    steps::Int=3,
    ∇H_kwargs::Union{NamedTuple,Dict}=(
        reconstruction_loglikelihood=decoder_loglikelihood,
        position_logprior=spherical_logprior,
        momentum_logprior=riemannian_logprior,
        G_inv=G_inv,
    ),
    tempering_schedule::Function=quadratic_tempering,
)</code></pre><p>Combines the leapfrog and tempering steps into a single function for the Riemannian Hamiltonian Variational Autoencoder (RHVAE).</p><p><strong>Arguments</strong></p><ul><li><code>x::AbstractArray</code>: The data to be processed. If <code>Array</code>, the last dimension must be of size 1.</li><li><code>zₒ::AbstractVector</code>: The initial latent variable. </li><li><code>Gₒ⁻¹::AbstractArray</code>: The initial inverse of the Riemannian metric tensor.</li><li><code>logdetGₒ::Union{&lt;:Number,AbstractVector}</code>: The log determinant of the initial Riemannian metric tensor. If vector, each element represents the log determinant of the metric tensor at the corresponding column of <code>zₒ</code>.</li><li><code>decoder::AbstractVariationalDecoder</code>: The decoder of the RHVAE model.</li><li><code>decoder_output::NamedTuple</code>: The output of the decoder.</li><li><code>metric_param::NamedTuple</code>: The parameters of the metric tensor.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>ϵ::Union{&lt;:Number,&lt;:AbstractVector}</code>: The step size for the leapfrog steps in the HMC algorithm. This can be a scalar or an array. Default is 0.01f0.  </li><li><code>K::Int</code>: The number of leapfrog steps to perform in the Hamiltonian Monte Carlo (HMC) algorithm. Default is 3.</li><li><code>βₒ::Number</code>: The initial inverse temperature for the tempering schedule. Default is 0.3f0.</li><li><code>steps::Int</code>: The number of fixed-point iterations to perform. Default is 3.</li><li><code>∇H_kwargs::Union{NamedTuple,Dict}</code>: Additional keyword arguments to be passed to the <code>∇hamiltonian</code> function. Default is a NamedTuple with <code>reconstruction_loglikelihood</code>, <code>position_logprior</code>, and <code>momentum_logprior</code>.</li><li><code>tempering_schedule::Function</code>: The function to compute the inverse temperature at each step in the HMC algorithm. Defaults to <code>quadratic_tempering</code>. This function must take three arguments: First, <code>βₒ</code>, an initial inverse temperature, second, <code>k</code>, the current step in the tempering schedule, and third, <code>K</code>, the total number of steps in the tempering schedule.</li></ul><p><strong>Returns</strong></p><ul><li>A <code>NamedTuple</code> with the following keys: <ul><li><code>z_init</code>: The initial latent variable. </li><li><code>ρ_init</code>: The initial momentum variable. </li><li><code>Ginv_init</code>: The initial inverse of the Riemannian metric tensor. </li><li><code>logdetG_init</code>: The initial log determinant of the Riemannian metric tensor.</li><li><code>z_final</code>: The final latent variable after <code>K</code> leapfrog steps. </li><li><code>ρ_final</code>: The final momentum variable after <code>K</code> leapfrog steps. </li><li><code>Ginv_final</code>: The final inverse of the Riemannian metric tensor after <code>K</code> leapfrog steps.</li><li><code>logdetG_final</code>: The final log determinant of the Riemannian metric tensor after <code>K</code> leapfrog steps.</li></ul></li><li>The decoder output at the final latent variable is also returned. Note: This is not in the same named tuple as the other outputs, but as a separate output.</li></ul><p><strong>Description</strong></p><p>The function first samples a random momentum variable <code>γₒ</code> from a standard normal distribution and scales it by the inverse square root of the initial inverse temperature <code>βₒ</code> to obtain the initial momentum variable <code>ρₒ</code>. Then, it performs <code>K</code> leapfrog steps, each followed by a tempering step, to generate a new sample from the latent space.</p><p><strong>Note</strong></p><p>Ensure the input data <code>x</code> and the initial latent variable <code>zₒ</code> match the expected input dimensionality for the RHVAE model.</p></div></section><section><div><pre><code class="language-julia hljs">general_leapfrog_tempering_step(
    x::AbstractArray,
    zₒ::AbstractVecOrMat,
    rhvae::RHVAE;
    ϵ::Union{&lt;:Number,&lt;:AbstractVector}=Float32(1E-4),
    K::Int=3,
    βₒ::Number=0.3f0,
    steps::Int=3,
    ∇H_kwargs::Union{NamedTuple,Dict}=(
        reconstruction_loglikelihood=decoder_loglikelihood,
        position_logprior=spherical_logprior,
        momentum_logprior=riemannian_logprior,
    ),
    G_inv::Function=G_inv,
    tempering_schedule::Function=quadratic_tempering,
)</code></pre><p>Combines the leapfrog and tempering steps into a single function for the Riemannian Hamiltonian Variational Autoencoder (RHVAE).</p><p><strong>Arguments</strong></p><ul><li><code>x::AbstractArray</code>: The data to be processed. If <code>Array</code>, the last dimension must be of size 1.</li><li><code>zₒ::AbstractVecOrMat</code>: The initial latent variable. </li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>ϵ::Union{&lt;:Number,&lt;:AbstractVector}</code>: The step size for the leapfrog steps in the HMC algorithm. This can be a scalar or an array. Default is 0.01f0.  </li><li><code>K::Int</code>: The number of leapfrog steps to perform in the Hamiltonian Monte Carlo (HMC) algorithm. Default is 3.</li><li><code>βₒ::Number</code>: The initial inverse temperature for the tempering schedule. Default is 0.3f0.</li><li><code>steps::Int</code>: The number of fixed-point iterations to perform. Default is 3.</li><li><code>∇H_kwargs::Union{NamedTuple,Dict}</code>: Additional keyword arguments to be passed to the <code>∇hamiltonian</code> function. Default is a NamedTuple with <code>reconstruction_loglikelihood</code>, <code>position_logprior</code>, and <code>momentum_logprior</code>.</li><li><code>tempering_schedule::Function</code>: The function to compute the inverse temperature at each step in the HMC algorithm. Defaults to <code>quadratic_tempering</code>. This function must take three arguments: First, <code>βₒ</code>, an initial inverse temperature, second, <code>k</code>, the current step in the tempering schedule, and third, <code>K</code>, the total number of steps in the tempering schedule.</li></ul><p><strong>Returns</strong></p><ul><li>A <code>NamedTuple</code> with the following keys: <ul><li><code>z_init</code>: The initial latent variable. </li><li><code>ρ_init</code>: The initial momentum variable. </li><li><code>Ginv_init</code>: The initial inverse of the Riemannian metric tensor. </li><li><code>z_final</code>: The final latent variable after <code>K</code> leapfrog steps. </li><li><code>ρ_final</code>: The final momentum variable after <code>K</code> leapfrog steps. </li><li><code>Ginv_final</code>: The final inverse of the Riemannian metric tensor after <code>K</code> leapfrog steps.</li></ul></li><li>The decoder output at the final latent variable is also returned. Note: This is not in the same named tuple as the other outputs, but as a separate output.</li></ul><p><strong>Description</strong></p><p>The function first samples a random momentum variable <code>γₒ</code> from a standard normal distribution and scales it by the inverse square root of the initial inverse temperature <code>βₒ</code> to obtain the initial momentum variable <code>ρₒ</code>. Then, it performs <code>K</code> leapfrog steps, each followed by a tempering step, to generate a new sample from the latent space.</p><p><strong>Note</strong></p><p>Ensure the input data <code>x</code> and the initial latent variable <code>zₒ</code> match the expected input dimensionality for the RHVAE model.</p></div></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AutoEncode.RHVAEs._log_p̄" href="#AutoEncode.RHVAEs._log_p̄"><code>AutoEncode.RHVAEs._log_p̄</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">_log_p̄(
    x::AbstractArray,
    rhvae::RHVAE{VAE{E,D}},
    rhvae_outputs::NamedTuple;
    reconstruction_loglikelihood::Function=decoder_loglikelihood,
    position_logprior::Function=spherical_logprior,
    momentum_logprior::Function=riemannian_logprior,
    prefactor::AbstractArray=ones(Float32, 3),
)</code></pre><p>This is an internal function used in <code>riemannian_hamiltonian_elbo</code> to compute the numerator of the unbiased estimator of the marginal likelihood. The function computes the sum of the log likelihood of the data given the latent variables, the log prior of the latent variables, and the log prior of the momentum variables.</p><pre><code class="nohighlight hljs">log p̄ = log p(x | zₖ) + log p(zₖ) + log p(ρₖ(zₖ))</code></pre><p><strong>Arguments</strong></p><ul><li><code>x::AbstractArray</code>: The input data. If <code>Array</code>, the last dimension must contain each of the data points.</li><li><code>rhvae::RHVAE{&lt;:VAE{&lt;:AbstractGaussianEncoder,&lt;:AbstractGaussianLogDecoder}}</code>: The Riemannian Hamiltonian Variational Autoencoder (RHVAE) model.</li><li><code>rhvae_outputs::NamedTuple</code>: The outputs of the RHVAE, including the final latent variables <code>zₖ</code> and the final momentum variables <code>ρₖ</code>.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>reconstruction_loglikelihood::Function</code>: The function to compute the log likelihood of the data given the latent variables. Default is <code>decoder_loglikelihood</code>.</li><li><code>position_logprior::Function</code>: The function to compute the log prior of the latent variables. Default is <code>spherical_logprior</code>.</li><li><code>momentum_logprior::Function</code>: The function to compute the log prior of the momentum variables. Default is <code>riemannian_logprior</code>.</li><li><code>prefactor::AbstractArray</code>: A 3-element array to scale the log likelihood, log prior of the latent variables, and log prior of the momentum variables. Default is an array of ones.</li></ul><p><strong>Returns</strong></p><ul><li><code>log_p̄::AbstractVector</code>: The first term of the log of the unbiased estimator of the marginal likelihood for each data point.</li></ul><p><strong>Note</strong></p><p>This is an internal function and should not be called directly. It is used as part of the <code>riemannian_hamiltonian_elbo</code> function.</p></div></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AutoEncode.RHVAEs._log_q̄" href="#AutoEncode.RHVAEs._log_q̄"><code>AutoEncode.RHVAEs._log_q̄</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">_log_q̄(
    rhvae::RHVAE,
    rhvae_outputs::NamedTuple,
    βₒ::Number;
    momentum_logprior::Function=riemannian_logprior,
    prefactor::AbstractArray=ones(Float32, 3),
)</code></pre><p>This is an internal function used in <code>riemannian_hamiltonian_elbo</code> to compute the second term of the unbiased estimator of the marginal likelihood. The function computes the sum of the log posterior of the initial latent variables and the log prior of the initial momentum variables, minus a term that depends on the dimensionality of the latent space and the initial temperature.</p><pre><code class="nohighlight hljs">    log q̄ = log q(zₒ) + log p(ρₒ) - d/2 log(βₒ)</code></pre><p><strong>Arguments</strong></p><ul><li><code>rhvae::RHVAE</code>: The Riemannian Hamiltonian Variational Autoencoder (RHVAE) model.</li><li><code>rhvae_outputs::NamedTuple</code>: The outputs of the RHVAE, including the initial latent variables <code>zₒ</code> and the initial momentum variables <code>ρₒ</code>.</li><li><code>βₒ::Number</code>: The initial temperature for the tempering steps.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>momentum_logprior::Function</code>: The function to compute the log prior of the momentum variables. Default is <code>riemannian_logprior</code>.</li><li><code>prefactor::AbstractArray</code>: A 3-element array to scale the log posterior of the initial latent variables, log prior of the initial momentum variables, and the tempering Jacobian term. Default is an array of ones.</li></ul><p><strong>Returns</strong></p><ul><li><code>log_q̄::Vector</code>: The second term of the log of the unbiased estimator of the   marginal likelihood for each data point.</li></ul><p><strong>Note</strong></p><p>This is an internal function and should not be called directly. It is used as part of the <code>riemannian_hamiltonian_elbo</code> function.</p></div></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AutoEncode.RHVAEs.riemannian_hamiltonian_elbo" href="#AutoEncode.RHVAEs.riemannian_hamiltonian_elbo"><code>AutoEncode.RHVAEs.riemannian_hamiltonian_elbo</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">riemannian_hamiltonian_elbo(
    rhvae::RHVAE,
    metric_param::NamedTuple,
    x::AbstractArray;
    ϵ::Union{&lt;:Number,&lt;:AbstractVector}=Float32(1E-4),
    K::Int=3,
    βₒ::Number=0.3f0,
    steps::Int=3,
    ∇H_kwargs::Union{NamedTuple,Dict}=(
        reconstruction_loglikelihood=decoder_loglikelihood,
        position_logprior=spherical_logprior,
        momentum_logprior=riemannian_logprior,
        G_inv=G_inv,
    ),
    tempering_schedule::Function=quadratic_tempering,
    return_outputs::Bool=false,
    logp_prefactor::AbstractArray=ones(Float32, 3),
    logq_prefactor::AbstractArray=ones(Float32, 3),
)</code></pre><p>Compute the Riemannian Hamiltonian Monte Carlo (RHMC) estimate of the evidence lower bound (ELBO) for a Riemannian Hamiltonian Variational Autoencoder (RHVAE).</p><p>This function takes as input an RHVAE, a NamedTuple of metric parameters, and a vector of input data <code>x</code>. It performs <code>K</code> RHMC steps with a leapfrog integrator and a tempering schedule to estimate the ELBO. The ELBO is computed as the difference between the <code>log p̄</code> and <code>log q̄</code> as</p><p>elbo = mean(log p̄ - log q̄),</p><p><strong>Arguments</strong></p><ul><li><code>rhvae::RHVAE</code>: The RHVAE used to encode the input data and decode the latent space.</li><li><code>metric_param::NamedTuple</code>: The parameters used to compute the metric tensor.</li><li><code>x::AbstractArray</code>: The input data. If <code>Array</code>, the last dimension must contain each of the data points.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>ϵ::Union{&lt;:Number,&lt;:AbstractVector}</code>: The step size for the leapfrog integrator (default is 0.01).</li><li><code>K::Int</code>: The number of RHMC steps (default is 3).</li><li><code>βₒ::Number</code>: The initial inverse temperature (default is 0.3).</li><li><code>steps::Int</code>: The number of leapfrog steps (default is 3).</li><li><code>∇H_kwargs::Union{NamedTuple,Dict}</code>: Additional keyword arguments to be passed to the <code>∇hamiltonian</code> function. Defaults to a NamedTuple with <code>:decoder_loglikelihood</code> set to <code>decoder_loglikelihood</code>, <code>:position_logprior</code> set to <code>spherical_logprior</code>, and <code>:momentum_logprior</code> set to <code>riemannian_logprior</code>.</li><li><code>G_inv::Function</code>: The function to compute the inverse of the Riemannian metric tensor. Defaults to <code>G_inv</code>.</li><li><code>tempering_schedule::Function</code>: The tempering schedule function used in the RHMC (default is <code>quadratic_tempering</code>).</li><li><code>return_outputs::Bool</code>: Whether to return the outputs of the RHVAE. Defaults to <code>false</code>. NOTE: This is necessary to avoid computing the forward pass twice when computing the loss function with regularization.</li><li><code>logp_prefactor::AbstractArray</code>: A 3-element array to scale the log likelihood, log prior of the latent variables, and log prior of the momentum variables. Default is an array of ones.</li><li><code>logq_prefactor::AbstractArray</code>: A 3-element array to scale the log posterior of the initial latent variables, log prior of the initial momentum variables, and the tempering Jacobian term. Default is an array of ones.</li></ul><p><strong>Returns</strong></p><ul><li><code>elbo::Number</code>: The RHMC estimate of the ELBO. If <code>return_outputs</code> is <code>true</code>, also returns the outputs of the RHVAE.</li></ul></div></section><section><div><pre><code class="language-julia hljs">riemannian_hamiltonian_elbo(
    rhvae::RHVAE,
    x::AbstractVector;
    K::Int=3,
    ϵ::Union{&lt;:Number,&lt;:AbstractVector}=Float32(1E-4),
    βₒ::Number=0.3f0,
    steps::Int=3,
    ∇H_kwargs::Union{NamedTuple,Dict}=(
        reconstruction_loglikelihood=decoder_loglikelihood,
        position_logprior=spherical_logprior,
        momentum_logprior=riemannian_logprior,
        G_inv=G_inv,
    ),
    tempering_schedule::Function=quadratic_tempering,
    return_outputs::Bool=false,
    logp_prefactor::AbstractArray=ones(Float32, 3),
    logq_prefactor::AbstractArray=ones(Float32, 3),
)</code></pre><p>Compute the Riemannian Hamiltonian Monte Carlo (RHMC) estimate of the evidence lower bound (ELBO) for a Riemannian Hamiltonian Variational Autoencoder (RHVAE).</p><p>This function takes as input an RHVAE, a NamedTuple of metric parameters, and a vector of input data <code>x</code>. It performs <code>K</code> RHMC steps with a leapfrog integrator and a tempering schedule to estimate the ELBO. The ELBO is computed as the difference between the <code>log p̄</code> and <code>log q̄</code> as</p><p>elbo = mean(log p̄ - log q̄)</p><p><strong>Arguments</strong></p><ul><li><code>rhvae::RHVAE</code>: The RHVAE used to encode the input data and decode the latent space.</li><li><code>x::AbstractVector</code>: The input data.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>∇H_kwargs::Union{NamedTuple,Dict}</code>: Additional keyword arguments to be passed to the <code>∇hamiltonian</code> function. Defaults to a NamedTuple with <code>:decoder_loglikelihood</code> set to <code>decoder_loglikelihood</code>, <code>:position_logprior</code> set to <code>spherical_logprior</code>, <code>:momentum_logprior</code> set to <code>riemannian_logprior</code>, and <code>:G_inv</code> set to <code>G_inv</code>.</li><li><code>K::Int</code>: The number of RHMC steps (default is 3).</li><li><code>ϵ::Union{&lt;:Number,&lt;:AbstractVector}</code>: The step size for the leapfrog integrator (default is 0.001).</li><li><code>βₒ::Number</code>: The initial inverse temperature (default is 0.3).</li><li><code>steps::Int</code>: The number of leapfrog steps (default is 3).</li><li><code>G_inv::Function</code>: The function to compute the inverse of the Riemannian metric tensor (default is <code>G_inv</code>).</li><li><code>tempering_schedule::Function</code>: The tempering schedule function used in the RHMC (default is <code>quadratic_tempering</code>).</li><li><code>return_outputs::Bool</code>: Whether to return the outputs of the RHVAE. Defaults to <code>false</code>. NOTE: This is necessary to avoid computing the forward pass twice when computing the loss function with regularization.</li><li><code>logp_prefactor::AbstractArray</code>: A 3-element array to scale the log likelihood, log prior of the latent variables, and log prior of the momentum variables. Default is an array of ones.</li><li><code>logq_prefactor::AbstractArray</code>: A 3-element array to scale the log posterior of the initial latent variables, log prior of the initial momentum variables, and the tempering Jacobian term. Default is an array of ones.</li></ul><p><strong>Returns</strong></p><ul><li><code>elbo::Number</code>: The RHMC estimate of the ELBO. If <code>return_outputs</code> is <code>true</code>, also returns the outputs of the RHVAE.</li></ul></div></section><section><div><pre><code class="language-julia hljs">riemannian_hamiltonian_elbo(
    rhvae::RHVAE,
    metric_param::NamedTuple,
    x_in::AbstractArray,
    x_out::AbstractArray;
    ϵ::Union{&lt;:Number,&lt;:AbstractVector}=Float32(1E-4),
    K::Int=3,
    βₒ::Number=0.3f0,
    steps::Int=3,
    ∇H_kwargs::Union{NamedTuple,Dict}=(
        reconstruction_loglikelihood=decoder_loglikelihood,
        position_logprior=spherical_logprior,
        momentum_logprior=riemannian_logprior,
        G_inv=G_inv,
    ),
    tempering_schedule::Function=quadratic_tempering,
    return_outputs::Bool=false,
    logp_prefactor::AbstractArray=ones(Float32, 3),
    logq_prefactor::AbstractArray=ones(Float32, 3),
)</code></pre><p>Compute the Riemannian Hamiltonian Monte Carlo (RHMC) estimate of the evidence lower bound (ELBO) for a Riemannian Hamiltonian Variational Autoencoder (RHVAE).</p><p>This function takes as input an RHVAE, a NamedTuple of metric parameters, and a vector of input data <code>x</code>. It performs <code>K</code> RHMC steps with a leapfrog integrator and a tempering schedule to estimate the ELBO. The ELBO is computed as the difference between the <code>log p̄</code> and <code>log q̄</code> as</p><p>elbo = mean(log p̄ - log q̄),</p><p><strong>Arguments</strong></p><ul><li><code>rhvae::RHVAE</code>: The RHVAE used to encode the input data and decode the latent space.</li><li><code>metric_param::NamedTuple</code>: The parameters used to compute the metric tensor.</li><li><code>x_in::AbstractArray</code>: Input data to the RHVAE encoder. The last dimension is taken as having each of the samples in a batch.</li><li><code>x_out::AbstractArray</code>: Target data to compute the reconstruction error. The last dimension is taken as having each of the samples in a batch.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>ϵ::Union{&lt;:Number,&lt;:AbstractVector}</code>: The step size for the leapfrog integrator (default is 0.01).</li><li><code>K::Int</code>: The number of RHMC steps (default is 3).</li><li><code>βₒ::Number</code>: The initial inverse temperature (default is 0.3).</li><li><code>steps::Int</code>: The number of leapfrog steps (default is 3).</li><li><code>∇H_kwargs::Union{NamedTuple,Dict}</code>: Additional keyword arguments to be passed to the <code>∇hamiltonian</code> function. Defaults to a NamedTuple with <code>:decoder_loglikelihood</code> set to <code>decoder_loglikelihood</code>, <code>:position_logprior</code> set to <code>spherical_logprior</code>, and <code>:momentum_logprior</code> set to <code>riemannian_logprior</code>.</li><li><code>G_inv::Function</code>: The function to compute the inverse of the Riemannian metric tensor. Defaults to <code>G_inv</code>.</li><li><code>tempering_schedule::Function</code>: The tempering schedule function used in the RHMC (default is <code>quadratic_tempering</code>).</li><li><code>return_outputs::Bool</code>: Whether to return the outputs of the RHVAE. Defaults to <code>false</code>. NOTE: This is necessary to avoid computing the forward pass twice when computing the loss function with regularization.</li><li><code>logp_prefactor::AbstractArray</code>: A 3-element array to scale the log likelihood, log prior of the latent variables, and log prior of the momentum variables. Default is an array of ones.</li><li><code>logq_prefactor::AbstractArray</code>: A 3-element array to scale the log posterior of the initial latent variables, log prior of the initial momentum variables, and the tempering Jacobian term. Default is an array of ones.</li></ul><p><strong>Returns</strong></p><ul><li><code>elbo::Number</code>: The RHMC estimate of the ELBO. If <code>return_outputs</code> is <code>true</code>, also returns the outputs of the RHVAE.</li></ul></div></section><section><div><pre><code class="language-julia hljs">riemannian_hamiltonian_elbo(
    rhvae::RHVAE,
    x_in::AbstractArray,
    x_out::AbstractArray;
    K::Int=3,
    ϵ::Union{&lt;:Number,&lt;:AbstractVector}=Float32(1E-4),
    βₒ::Number=0.3f0,
    steps::Int=3,
    ∇H_kwargs::Union{NamedTuple,Dict}=(
        reconstruction_loglikelihood=decoder_loglikelihood,
        position_logprior=spherical_logprior,
        momentum_logprior=riemannian_logprior,
        G_inv=G_inv,
    ),
    tempering_schedule::Function=quadratic_tempering,
    return_outputs::Bool=false,
    logp_prefactor::AbstractArray=ones(Float32, 3),
    logq_prefactor::AbstractArray=ones(Float32, 3),
)</code></pre><p>Compute the Riemannian Hamiltonian Monte Carlo (RHMC) estimate of the evidence lower bound (ELBO) for a Riemannian Hamiltonian Variational Autoencoder (RHVAE).</p><p>This function takes as input an RHVAE, a NamedTuple of metric parameters, and a vector of input data <code>x</code>. It performs <code>K</code> RHMC steps with a leapfrog integrator and a tempering schedule to estimate the ELBO. The ELBO is computed as the difference between the <code>log p̄</code> and <code>log q̄</code> as</p><p>elbo = mean(log p̄ - log q̄).</p><p><strong>Arguments</strong></p><ul><li><code>rhvae::RHVAE</code>: The RHVAE used to encode the input data and decode the latent space.</li><li><code>x_in::AbstractArray</code>: Input data to the RHVAE encoder. The last dimension is taken as having each of the samples in a batch.</li><li><code>x_out::AbstractArray</code>: Target data to compute the reconstruction error. The last dimension is taken as having each of the samples in a batch.</li></ul><p><strong>Optional Keyword Arguments</strong></p><ul><li><code>∇H_kwargs::Union{NamedTuple,Dict}</code>: Additional keyword arguments to be passed to the <code>∇hamiltonian</code> function. Defaults to a NamedTuple with <code>:decoder_loglikelihood</code> set to <code>decoder_loglikelihood</code>, <code>:position_logprior</code> set to <code>spherical_logprior</code>, <code>:momentum_logprior</code> set to <code>riemannian_logprior</code>, and <code>:G_inv</code> set to <code>G_inv</code>.</li><li><code>K::Int</code>: The number of RHMC steps (default is 3).</li><li><code>ϵ::Union{&lt;:Number,&lt;:AbstractVector}</code>: The step size for the leapfrog integrator (default is 0.001).</li><li><code>βₒ::Number</code>: The initial inverse temperature (default is 0.3).</li><li><code>steps::Int</code>: The number of leapfrog steps (default is 3).</li><li><code>G_inv::Function</code>: The function to compute the inverse of the Riemannian metric tensor (default is <code>G_inv</code>).</li><li><code>tempering_schedule::Function</code>: The tempering schedule function used in the RHMC (default is <code>quadratic_tempering</code>).</li><li><code>return_outputs::Bool</code>: Whether to return the outputs of the RHVAE. Defaults to <code>false</code>. NOTE: This is necessary to avoid computing the forward pass twice when computing the loss function with regularization.</li><li><code>logp_prefactor::AbstractArray</code>: A 3-element array to scale the log likelihood, log prior of the latent variables, and log prior of the momentum variables. Default is an array of ones.</li><li><code>logq_prefactor::AbstractArray</code>: A 3-element array to scale the log posterior of the initial latent variables, log prior of the initial momentum variables, and the tempering Jacobian term. Default is an array of ones.</li></ul><p><strong>Returns</strong></p><ul><li><code>elbo::Number</code>: The RHMC estimate of the ELBO. If <code>return_outputs</code> is <code>true</code>, also returns the outputs of the RHVAE.</li></ul></div></section></article><h2 id="Default-initializations"><a class="docs-heading-anchor" href="#Default-initializations">Default initializations</a><a id="Default-initializations-1"></a><a class="docs-heading-anchor-permalink" href="#Default-initializations" title="Permalink"></a></h2><p><code>AutoEncode.jl</code> provides default initializations for both the metric tensor network and the RHVAE. Although less flexible than defining your own initial networks, these can serve as a good starting point for your experiments.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AutoEncode.RHVAEs.MetricChain-Tuple{Int64, Int64, Vector{&lt;:Int64}, Vector{&lt;:Function}, Function}" href="#AutoEncode.RHVAEs.MetricChain-Tuple{Int64, Int64, Vector{&lt;:Int64}, Vector{&lt;:Function}, Function}"><code>AutoEncode.RHVAEs.MetricChain</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">MetricChain(
    n_input::Int,
    n_latent::Int,
    metric_neurons::Vector{&lt;:Int},
    metric_activation::Vector{&lt;:Function},
    output_activation::Function;
    init::Function=Flux.glorot_uniform
) -&gt; MetricChain</code></pre><p>Construct a <code>MetricChain</code> for computing the Riemannian metric tensor in the latent space.</p><p><strong>Arguments</strong></p><ul><li><code>n_input::Int</code>: The number of input features.</li><li><code>n_latent::Int</code>: The dimension of the latent space.</li><li><code>metric_neurons::Vector{&lt;:Int}</code>: The number of neurons in each hidden layer of the MLP.</li><li><code>metric_activation::Vector{&lt;:Function}</code>: The activation function for each hidden layer of the MLP.</li><li><code>output_activation::Function</code>: The activation function for the output layer.</li><li><code>init::Function</code>: The initialization function for the weights in the layers (default is <code>Flux.glorot_uniform</code>).</li></ul><p><strong>Returns</strong></p><ul><li><code>MetricChain</code>: A <code>MetricChain</code> object that includes the MLP, and two dense layers for computing the elements of a lower-triangular matrix used to compute the Riemannian metric tensor in latent space.</li></ul></div></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AutoEncode.RHVAEs.RHVAE-Tuple{AutoEncode.VAEs.VAE, AutoEncode.RHVAEs.MetricChain, AbstractArray{AbstractFloat}, AbstractFloat, AbstractFloat}" href="#AutoEncode.RHVAEs.RHVAE-Tuple{AutoEncode.VAEs.VAE, AutoEncode.RHVAEs.MetricChain, AbstractArray{AbstractFloat}, AbstractFloat, AbstractFloat}"><code>AutoEncode.RHVAEs.RHVAE</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">RHVAE(
    vae::VAE, 
    metric_chain::MetricChain, 
    centroids_data::AbstractArray, 
    T::Number, 
    λ::Number
)</code></pre><p>Construct a Riemannian Hamiltonian Variational Autoencoder (RHVAE) from a standard VAE and a metric chain.</p><p><strong>Arguments</strong></p><ul><li><code>vae::VAE</code>: A standard Variational Autoencoder (VAE) model.</li><li><code>metric_chain::MetricChain</code>: A chain of metrics to be used for the Riemannian Hamiltonian Monte Carlo (RHMC) sampler.</li><li><code>centroids_data::AbstractArray</code>: An array of data centroids. Each column represents a centroid. <code>N</code> is a subtype of <code>Number</code>.</li><li><code>T::N</code>: The temperature parameter for the inverse metric tensor. <code>N</code> is a subtype of <code>Number</code>.</li><li><code>λ::N</code>: The regularization parameter for the inverse metric tensor. <code>N</code> is a subtype of <code>Number</code>.</li></ul><p><strong>Returns</strong></p><ul><li>A new <code>RHVAE</code> object.</li></ul><p><strong>Description</strong></p><p>The constructor initializes the latent centroids and the metric tensor <code>M</code> to their default values. The latent centroids are initialized to a zero matrix of the same size as <code>centroids_data</code>, and <code>M</code> is initialized to a 3D array of identity matrices, one for each centroid.</p></div></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../hvae/">« HVAE</a><a class="docs-footer-nextpage" href="../diffgeo/">Differential Geometry »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.4.0 on <span class="colophon-date" title="Monday 29 April 2024 19:47">Monday 29 April 2024</span>. Using Julia version 1.10.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
