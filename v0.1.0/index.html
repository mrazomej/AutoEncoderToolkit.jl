<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · AutoEncoderToolkit</title><meta name="title" content="Home · AutoEncoderToolkit"/><meta property="og:title" content="Home · AutoEncoderToolkit"/><meta property="twitter:title" content="Home · AutoEncoderToolkit"/><meta name="description" content="Documentation for AutoEncoderToolkit."/><meta property="og:description" content="Documentation for AutoEncoderToolkit."/><meta property="twitter:description" content="Documentation for AutoEncoderToolkit."/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href><img class="docs-light-only" src="assets/logo.svg" alt="AutoEncoderToolkit logo"/><img class="docs-dark-only" src="assets/logo-dark.svg" alt="AutoEncoderToolkit logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href>AutoEncoderToolkit</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a><ul class="internal"><li><a class="tocitem" href="#Installation"><span>Installation</span></a></li><li><a class="tocitem" href="#Design"><span>Design</span></a></li><li><a class="tocitem" href="#Implemented-Autoencoders"><span>Implemented Autoencoders</span></a></li><li><a class="tocitem" href="#GPU-support"><span>GPU support</span></a></li></ul></li><li><a class="tocitem" href="quickstart/">Quick Start</a></li><li><a class="tocitem" href="encoders/">Encoders &amp; Decoders</a></li><li><a class="tocitem" href="layers/">Custom Layers</a></li><li><a class="tocitem" href="ae/">Deterministic Autoencoders</a></li><li><a class="tocitem" href="vae/">VAE / β-VAE</a></li><li><a class="tocitem" href="mmdvae/">MMD-VAE (InfoVAE)</a></li><li><a class="tocitem" href="infomaxvae/">InfoMax-VAE</a></li><li><a class="tocitem" href="hvae/">HVAE</a></li><li><a class="tocitem" href="rhvae/">RHVAE</a></li><li><a class="tocitem" href="diffgeo/">Differential Geometry</a></li><li><a class="tocitem" href="utils/">Utilities</a></li><li><a class="tocitem" href="guidelines/">Community Guidelines</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="AutoEncoderToolkit.jl"><a class="docs-heading-anchor" href="#AutoEncoderToolkit.jl">AutoEncoderToolkit.jl</a><a id="AutoEncoderToolkit.jl-1"></a><a class="docs-heading-anchor-permalink" href="#AutoEncoderToolkit.jl" title="Permalink"></a></h1><p>Welcome to the <code>AutoEncoderToolkit.jl</code> documentation. This package provides a simple interface for training and using <a href="https://fluxml.ai">Flux.jl</a>-based autoencoders and variational autoencoders in Julia.</p><h2 id="Installation"><a class="docs-heading-anchor" href="#Installation">Installation</a><a id="Installation-1"></a><a class="docs-heading-anchor-permalink" href="#Installation" title="Permalink"></a></h2><p>You can install <code>AutoEncoderToolkit.jl</code> using the Julia package manager. From the Julia REPL, type <code>]</code> to enter the Pkg REPL mode and run:</p><pre><code class="language-julia-repl hljs">add AutoEncoderToolkit</code></pre><h2 id="Design"><a class="docs-heading-anchor" href="#Design">Design</a><a id="Design-1"></a><a class="docs-heading-anchor-permalink" href="#Design" title="Permalink"></a></h2><p>The idea behind <code>AutoEncoderToolkit.jl</code> is to take advantage of Julia&#39;s multiple dispatch to provide a simple and flexible interface for training and using different types of autoencoders. The package is designed to be modular and allow the user to easily define and test custom encoder and decoder architectures. Moreover, when it comes to variational autoencoders, <code>AutoEncoderToolkit.jl</code> takes a probabilistic perspective, where the type of encoders and decoders defines (via multiple dispatch) the corresponding distribution used within the corresponding loss function.</p><p>For example, assume you want to train a variational autoencoder with convolutional layers in the encoder and deconvolutional layers in the decoder on the <a href="https://en.wikipedia.org/wiki/MNIST_database"><code>MNIST</code></a> dataset. You can easily do this as follows:</p><p>Let&#39;s begin by defining the encoder. For this, we will use the <code>JointGaussianLogEncoder</code> type, which is a simple encoder that takes a <code>Flux.Chain</code> for the shared layers between the mean and log-variance layers and two <code>Flux.Dense</code> (or <code>Flux.Chain</code>) layers for the last layers of the encoder.</p><pre><code class="language-julia hljs"># Define dimensionality of latent space
n_latent = 2

# Define number of initial channels
n_channels_init = 128

# Define convolutional layers
conv_layers = Flux.Chain(
    # First convolutional layer
    Flux.Conv((3, 3), 1 =&gt; n_channels_init, Flux.relu; stride=2, pad=1),
    # Second convolutional layer
    Flux.Conv(
        (3, 3), n_channels_init =&gt; n_channels_init * 2, Flux.relu;
        stride=2, pad=1
    ),
    # Flatten the output
    AutoEncoderToolkit.Flatten()
)

# Define layers for µ and log(σ)
µ_layer = Flux.Dense(n_channels_init * 2 * 7 * 7, n_latent, Flux.identity)
logσ_layer = Flux.Dense(n_channels_init * 2 * 7 * 7, n_latent, Flux.identity)

# build encoder
encoder = AutoEncoderToolkit.JointGaussianLogEncoder(conv_layers, µ_layer, logσ_layer)</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>The <code>Flatten</code> layer is a custom layer defined in <code>AutoEncoderToolkit.jl</code> that flattens the output into a 1D vector. This flattening operation is necessary because the output of the convolutional layers is a 4D tensor, while the input to the <code>µ</code> and <code>log(σ)</code> layers is a 1D vector. The custom layer is  needed to be able to save the model and load it later as <code>BSON</code> and <code>JLD2</code> do not play well with anonymous functions.</p></div></div><p>For the decoder, given the binary nature of the <code>MNIST</code> dataset, we expect the output to be a <code>Bernoulli</code> distribution. We can define the decoder as follows:</p><pre><code class="language-julia hljs"># Define deconvolutional layers
deconv_layers = Flux.Chain(
    # Define linear layer out of latent space
    Flux.Dense(n_latent =&gt; n_channels_init * 2 * 7 * 7, Flux.identity),
    # Unflatten input using custom Reshape layer
    AutoEncoderToolkit.Reshape(7, 7, n_channels_init * 2, :),
    # First transposed convolutional layer
    Flux.ConvTranspose(
        (4, 4), n_channels_init * 2 =&gt; n_channels_init, Flux.relu;
        stride=2, pad=1
    ),
    # Second transposed convolutional layer
    Flux.ConvTranspose(
        (4, 4), n_channels_init =&gt; 1, Flux.relu;
        stride=2, pad=1
    ),
    # Add normalization layer
    Flux.BatchNorm(1, Flux.sigmoid),
)

# Define decoder
decoder = AutoEncoderToolkit.BernoulliDecoder(deconv_layers)</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Again, the custom <code>Reshape</code> layer is used to reshape the output of the linear layer to the shape expected by the transposed convolutional layers. This custom layer is needed to be able to save the model and load it later.</p></div></div><p>By defining the decoder as a <code>BernoulliDecoder</code>, <code>AutoEncoderToolkit.jl</code> already knows the log-likehood function to use when training the model. We can then simply define our variational autoencoder by combining the encoder and decoder as</p><pre><code class="language-julia hljs"># Define variational autoencoder
vae = encoder * decoder</code></pre><p>If for any reason we were curious to explore a different distribution for the decoder, for example, a <code>Normal</code> distribution with constant variance, it would be as simple as defining the decoder as a <code>SimpleGaussianDecoder</code>.</p><pre><code class="language-julia hljs"># Define decoder with Normal likelihood function
decoder = AutoEncoderToolkit.SimpleGaussianDecoder(deconv_layers)

# Re-defining the variational autoencoder
vae = encoder * decoder</code></pre><p>Everything else in our training pipeline would remain the same thanks to multiple dispatch.</p><p>Furthermore, let&#39;s say that we would like to use a different flavor for our variational autoencoder. In particular the <code>InfoVAE</code> (also known as <code>MMD-VAE</code>) includes extra terms in the loss function to maximize mutual information between the latent space and the input data. We can easily take our <code>vae</code> model and convert it into a <code>MMDVAE</code>-type object from the <code>MMDVAEs</code> submodule as follows:</p><pre><code class="language-julia hljs">mmdvae = AutoEncoderToolkit.MMDVAEs.MMDVAE(vae)</code></pre><p>This is the power of <code>AutoEncoderToolkit.jl</code> and Julia&#39;s multiple dispatch!</p><h2 id="Implemented-Autoencoders"><a class="docs-heading-anchor" href="#Implemented-Autoencoders">Implemented Autoencoders</a><a id="Implemented-Autoencoders-1"></a><a class="docs-heading-anchor-permalink" href="#Implemented-Autoencoders" title="Permalink"></a></h2><table><tr><th style="text-align: right">model</th><th style="text-align: right">module</th><th style="text-align: right">description</th></tr><tr><td style="text-align: right">Autoencoder</td><td style="text-align: right"><a href="ae/#AEsmodule"><code>AEs</code></a></td><td style="text-align: right">Vanilla deterministic autoencoder</td></tr><tr><td style="text-align: right">Variational Autoencoder</td><td style="text-align: right"><a href="vae/#VAEsmodule"><code>VAEs</code></a></td><td style="text-align: right">Vanilla variational autoencoder</td></tr><tr><td style="text-align: right">β-VAE</td><td style="text-align: right"><a href="vae/#VAEsmodule"><code>VAEs</code></a></td><td style="text-align: right">beta-VAE to weigh the reconstruction vs. KL divergence in ELBO</td></tr><tr><td style="text-align: right">MMD-VAEs</td><td style="text-align: right"><a href="mmdvae/#MMDVAEsmodule"><code>MMDs</code></a></td><td style="text-align: right">Maximum-Mean Discrepancy Variational Autoencoders</td></tr><tr><td style="text-align: right">InfoMax-VAEs</td><td style="text-align: right"><a href="infomaxvae/#InfoMaxVAEsmodule"><code>InfoMaxVAEs</code></a></td><td style="text-align: right">Information Maximization Variational Autoencoders</td></tr><tr><td style="text-align: right">Hamiltonian VAE</td><td style="text-align: right"><a href="hvae/#HVAEsmodule"><code>HVAEs</code></a></td><td style="text-align: right">Hamiltonian Variational Autoencoders</td></tr><tr><td style="text-align: right">Riemannian Hamiltonian-VAE</td><td style="text-align: right"><a href="rhvae/#RHVAEsmodule"><code>RHVAEs</code></a></td><td style="text-align: right">Riemannian-Hamiltonian Variational Autoencoder</td></tr></table><div class="admonition is-success"><header class="admonition-header">Looking for contributors!</header><div class="admonition-body"><p>If you are interested in contributing to the package to add a new model, please check the <a href="https://github.com/mrazomej/AutoEncoderToolkit.jl">GitHub repository</a>. We are always  looking to expand the list of available models. And <code>AutoEncoderToolkit.jl</code>&#39;s  structure should make it relatively easy.</p></div></div><h2 id="GPU-support"><a class="docs-heading-anchor" href="#GPU-support">GPU support</a><a id="GPU-support-1"></a><a class="docs-heading-anchor-permalink" href="#GPU-support" title="Permalink"></a></h2><p><code>AutoEncoderToolkit.jl</code> supports GPU training out of the box for <code>CUDA.jl</code>-compatible GPUs. The <code>CUDA</code> functionality is provided as an extension. Therefore, to train a model on the GPU, simply import <code>CUDA</code> into the current environment, then move the model and data to the GPU. The rest of the training pipeline remains the same.</p></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="quickstart/">Quick Start »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.5.0 on <span class="colophon-date" title="Monday 8 July 2024 20:05">Monday 8 July 2024</span>. Using Julia version 1.10.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
